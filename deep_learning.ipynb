{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy\n",
    "import os\n",
    "import pandas\n",
    "import tensorflow\n",
    "\n",
    "from datetime import *\n",
    "from sklearn.model_selection import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.regularizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set NVIDIA GeForce RTX 3060 memory limit in MB\n",
    "GPU_LIM_MB = 1_024 * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve a list of available GPUs\n",
    "gpus = tensorflow.config.list_physical_devices('GPU')\n",
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the memory limit for the first GPU\n",
    "if gpus:\n",
    "    try:\n",
    "        tensorflow.config.set_visible_devices(gpus[0], 'GPU')\n",
    "        tensorflow.config.experimental.set_virtual_device_configuration(gpus[0], [tensorflow.config.experimental.VirtualDeviceConfiguration(memory_limit=GPU_LIM_MB)])\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>board</th>\n",
       "      <th>side</th>\n",
       "      <th>piece</th>\n",
       "      <th>atk</th>\n",
       "      <th>move</th>\n",
       "      <th>river</th>\n",
       "      <th>trap</th>\n",
       "      <th>den</th>\n",
       "      <th>score</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l-r---E-T-d-----C---p---W-------------w---P---...</td>\n",
       "      <td>-1</td>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>G7G6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l--r--E-T-d-----C---p---W-------------w---P---...</td>\n",
       "      <td>1</td>\n",
       "      <td>r</td>\n",
       "      <td>1</td>\n",
       "      <td>A3A4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>l--r--E-T-d-----C---p---W-------------w---P---...</td>\n",
       "      <td>-1</td>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>G6G5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>l--r--E-T-d-----C---p---W------------w----P---...</td>\n",
       "      <td>1</td>\n",
       "      <td>w</td>\n",
       "      <td>4</td>\n",
       "      <td>E3E2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>l--r--E-T-d-----C---p---W------------w----P---...</td>\n",
       "      <td>-1</td>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>G5G4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               board  side piece  atk  move  \\\n",
       "0  l-r---E-T-d-----C---p---W-------------w---P---...    -1     R    1  G7G6   \n",
       "1  l--r--E-T-d-----C---p---W-------------w---P---...     1     r    1  A3A4   \n",
       "2  l--r--E-T-d-----C---p---W-------------w---P---...    -1     R    1  G6G5   \n",
       "3  l--r--E-T-d-----C---p---W------------w----P---...     1     w    4  E3E2   \n",
       "4  l--r--E-T-d-----C---p---W------------w----P---...    -1     R    1  G5G4   \n",
       "\n",
       "   river  trap  den  score  winner  \n",
       "0      0     0    0      0       0  \n",
       "1      0     0    0      0       0  \n",
       "2      0     0    0      0       0  \n",
       "3      0     0    0      0       0  \n",
       "4      0     0    0      0       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = pandas.read_csv('animal_chess.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[:40_000_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the total number of rows\n",
    "count = len(df)\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "board     ----r-E-Tl-----WC--d---------p------L--R--P---...\n",
       "side                                                     -1\n",
       "piece                                                     L\n",
       "atk                                                       0\n",
       "move                                                   F1E1\n",
       "river                                                     0\n",
       "trap                                                      1\n",
       "den                                                       0\n",
       "score                                                   -90\n",
       "winner                                                    0\n",
       "Name: 32, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the sample at index 32\n",
    "sample = df.iloc[32]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode chess pieces to integer\n",
    "def encode_piece(piece_char):\n",
    "    piece_mapping = {'-': 0, 'r': 1, 'c': 2, 'd': 3, 'w': 4, 'p': 5, 't': 6, 'l': 7, 'e': 8, 'R': -1, 'C': -2, 'D': -3, 'W': -4, 'P': -5, 'T': -6, 'L': -7, 'E': -8}\n",
    "    return piece_mapping.get(piece_char, 0)\n",
    "\n",
    "encode_piece(sample['piece'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  7.,  0.,  0., -7.,  0.,  0.],\n",
       "       [ 0.,  0.,  3.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  5.,  0.,  0.,  4.],\n",
       "       [ 0.,  0.,  0.,  0., -1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [-8., -4.,  0.,  0., -5.,  0.,  0.],\n",
       "       [ 0., -2.,  0.,  0.,  0., -3.,  0.],\n",
       "       [-6.,  0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode chess board to matrix\n",
    "def encode_board(board_str):\n",
    "    board_matrix = numpy.zeros((9, 7))\n",
    "    for i, piece in enumerate(board_str[::-1]):\n",
    "        row, col = divmod(i, 9)\n",
    "        board_matrix[col][row] = encode_piece(piece)\n",
    "    return numpy.flip(numpy.flip(board_matrix, 0), 1)\n",
    "\n",
    "encode_board(sample['board'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.,  0.,  0., ...,  0.,  0., -7.],\n",
       "       [ 7.,  0.,  0., ...,  0.,  0., -7.],\n",
       "       [ 7.,  0.,  0., ...,  0.,  0., -7.],\n",
       "       ...,\n",
       "       [ 7.,  0.,  0., ...,  0.,  0., -7.],\n",
       "       [ 7.,  0.,  0., ...,  0.,  0., -7.],\n",
       "       [ 0.,  7.,  0., ...,  0.,  0., -7.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode all chess boards\n",
    "df['board_encoded'] = df['board'].apply(encode_board)\n",
    "board_matrix_flattened = numpy.array(df['board_encoded'].tolist()).reshape(count, -1)\n",
    "board_matrix_flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000000, 63), (40000000,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare data for model training\n",
    "X = numpy.array(df['board_encoded'].tolist()).reshape(count, -1)\n",
    "y = df['score'].values\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Keras session\n",
    "def reset_keras():\n",
    "    tensorflow.keras.backend.clear_session()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model architecture\n",
    "def build_model(input_shape, activation='relu'):\n",
    "    # Create a sequential model\n",
    "    model = Sequential([\n",
    "        # Input layer specifies the shape of the input data\n",
    "        Input(shape=input_shape),\n",
    "        # First convolution layer with 128 filters\n",
    "        Conv2D(128, (3, 3), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Activation(activation),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        # Second convolution layer with 256 filters\n",
    "        Conv2D(256, (3, 3), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Activation(activation),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        # Flatten the output from 2D to 1D before passing to the dense layer\n",
    "        Flatten(),\n",
    "        Dense(2048, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dropout(0.5),\n",
    "        # Output layer with linear activation to predict a continuous value\n",
    "        Dense(1, activation='linear')\n",
    "    ])\n",
    "    # Compile the model with Adam optimizer and mean squared error loss\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='mean_squared_error', metrics=['mae'])\n",
    "    # Return the model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the neural network model with the specified input shape and activation function\n",
    "model = build_model((9, 7, 1), activation='leaky_relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up TensorBoard logging with a timestamped directory to monitor the training process\n",
    "log_dir = os.path.join(\"logs\", \"fit\", datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize callbacks for adaptive learning rate, early stopping to prevent overfitting, and saving the best model\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint(\"best_model.h5\", monitor='val_loss', save_best_only=True, save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "125000/125000 [==============================] - 512s 4ms/step - loss: 257.3707 - mae: 7.4133 - val_loss: 131.0538 - val_mae: 8.6071 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "125000/125000 [==============================] - 505s 4ms/step - loss: 82.0756 - mae: 4.8368 - val_loss: 42.3326 - val_mae: 3.4605 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "125000/125000 [==============================] - 507s 4ms/step - loss: 65.6281 - mae: 4.3441 - val_loss: 46.7153 - val_mae: 4.2931 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "125000/125000 [==============================] - 504s 4ms/step - loss: 57.8100 - mae: 4.0851 - val_loss: 36.1581 - val_mae: 3.7421 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      "125000/125000 [==============================] - 505s 4ms/step - loss: 53.1850 - mae: 3.9233 - val_loss: 27.1005 - val_mae: 2.3402 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "125000/125000 [==============================] - 505s 4ms/step - loss: 49.9841 - mae: 3.7986 - val_loss: 23.8094 - val_mae: 2.2772 - lr: 1.0000e-04\n",
      "Epoch 7/50\n",
      "125000/125000 [==============================] - 506s 4ms/step - loss: 47.7939 - mae: 3.7104 - val_loss: 20.8071 - val_mae: 2.1380 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "125000/125000 [==============================] - 504s 4ms/step - loss: 46.0538 - mae: 3.6387 - val_loss: 19.8196 - val_mae: 1.9943 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "125000/125000 [==============================] - 505s 4ms/step - loss: 44.5661 - mae: 3.5772 - val_loss: 21.6051 - val_mae: 2.3084 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "125000/125000 [==============================] - 507s 4ms/step - loss: 43.3095 - mae: 3.5195 - val_loss: 19.5186 - val_mae: 2.2667 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "125000/125000 [==============================] - 504s 4ms/step - loss: 42.1942 - mae: 3.4743 - val_loss: 20.6755 - val_mae: 2.5249 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "125000/125000 [==============================] - 506s 4ms/step - loss: 41.3413 - mae: 3.4351 - val_loss: 15.7671 - val_mae: 1.7821 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "125000/125000 [==============================] - 509s 4ms/step - loss: 40.5698 - mae: 3.3993 - val_loss: 20.7248 - val_mae: 2.3637 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "125000/125000 [==============================] - 652s 5ms/step - loss: 39.8428 - mae: 3.3665 - val_loss: 17.1474 - val_mae: 2.0981 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "125000/125000 [==============================] - 758s 6ms/step - loss: 39.2303 - mae: 3.3366 - val_loss: 16.7734 - val_mae: 1.9765 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "125000/125000 [==============================] - 703s 6ms/step - loss: 38.6571 - mae: 3.3094 - val_loss: 14.6529 - val_mae: 1.7522 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "125000/125000 [==============================] - 629s 5ms/step - loss: 38.0673 - mae: 3.2847 - val_loss: 15.6029 - val_mae: 1.8651 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "125000/125000 [==============================] - 658s 5ms/step - loss: 37.5798 - mae: 3.2594 - val_loss: 16.0580 - val_mae: 2.0711 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "125000/125000 [==============================] - 745s 6ms/step - loss: 37.2179 - mae: 3.2416 - val_loss: 14.7247 - val_mae: 1.7004 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "125000/125000 [==============================] - 689s 6ms/step - loss: 36.8116 - mae: 3.2191 - val_loss: 14.8816 - val_mae: 1.8176 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "125000/125000 [==============================] - 695s 6ms/step - loss: 36.4802 - mae: 3.2050 - val_loss: 15.3371 - val_mae: 1.8358 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "125000/125000 [==============================] - 714s 6ms/step - loss: 30.6014 - mae: 2.8420 - val_loss: 9.5367 - val_mae: 1.3615 - lr: 2.0000e-05\n",
      "Epoch 23/50\n",
      "125000/125000 [==============================] - 717s 6ms/step - loss: 29.7664 - mae: 2.8186 - val_loss: 9.0389 - val_mae: 1.2952 - lr: 2.0000e-05\n",
      "Epoch 24/50\n",
      "125000/125000 [==============================] - 711s 6ms/step - loss: 29.4665 - mae: 2.8138 - val_loss: 8.6455 - val_mae: 1.2845 - lr: 2.0000e-05\n",
      "Epoch 25/50\n",
      "125000/125000 [==============================] - 710s 6ms/step - loss: 29.1753 - mae: 2.8084 - val_loss: 9.2056 - val_mae: 1.4134 - lr: 2.0000e-05\n",
      "Epoch 26/50\n",
      "125000/125000 [==============================] - 627s 5ms/step - loss: 29.0980 - mae: 2.8066 - val_loss: 8.8433 - val_mae: 1.3806 - lr: 2.0000e-05\n",
      "Epoch 27/50\n",
      "125000/125000 [==============================] - 682s 5ms/step - loss: 28.8917 - mae: 2.8022 - val_loss: 8.4681 - val_mae: 1.3749 - lr: 2.0000e-05\n",
      "Epoch 28/50\n",
      "125000/125000 [==============================] - 697s 6ms/step - loss: 28.7507 - mae: 2.8015 - val_loss: 8.2777 - val_mae: 1.3206 - lr: 2.0000e-05\n",
      "Epoch 29/50\n",
      "125000/125000 [==============================] - 559s 4ms/step - loss: 28.6502 - mae: 2.7994 - val_loss: 8.5765 - val_mae: 1.4151 - lr: 2.0000e-05\n",
      "Epoch 30/50\n",
      "125000/125000 [==============================] - 514s 4ms/step - loss: 28.5472 - mae: 2.7968 - val_loss: 8.0630 - val_mae: 1.3214 - lr: 2.0000e-05\n",
      "Epoch 31/50\n",
      "125000/125000 [==============================] - 513s 4ms/step - loss: 28.4375 - mae: 2.7951 - val_loss: 7.8877 - val_mae: 1.2693 - lr: 2.0000e-05\n",
      "Epoch 32/50\n",
      "125000/125000 [==============================] - 513s 4ms/step - loss: 28.3306 - mae: 2.7942 - val_loss: 8.2961 - val_mae: 1.4032 - lr: 2.0000e-05\n",
      "Epoch 33/50\n",
      "125000/125000 [==============================] - 516s 4ms/step - loss: 28.2622 - mae: 2.7915 - val_loss: 8.0955 - val_mae: 1.3215 - lr: 2.0000e-05\n",
      "Epoch 34/50\n",
      "125000/125000 [==============================] - 514s 4ms/step - loss: 28.1693 - mae: 2.7894 - val_loss: 7.8774 - val_mae: 1.3140 - lr: 2.0000e-05\n",
      "Epoch 35/50\n",
      "125000/125000 [==============================] - 514s 4ms/step - loss: 28.1103 - mae: 2.7873 - val_loss: 8.9920 - val_mae: 1.5772 - lr: 2.0000e-05\n",
      "Epoch 36/50\n",
      "125000/125000 [==============================] - 514s 4ms/step - loss: 28.0966 - mae: 2.7856 - val_loss: 7.8001 - val_mae: 1.3260 - lr: 2.0000e-05\n",
      "Epoch 37/50\n",
      "125000/125000 [==============================] - 515s 4ms/step - loss: 27.9728 - mae: 2.7831 - val_loss: 7.6617 - val_mae: 1.2937 - lr: 2.0000e-05\n",
      "Epoch 38/50\n",
      "125000/125000 [==============================] - 513s 4ms/step - loss: 27.8619 - mae: 2.7812 - val_loss: 7.7165 - val_mae: 1.2439 - lr: 2.0000e-05\n",
      "Epoch 39/50\n",
      "125000/125000 [==============================] - 514s 4ms/step - loss: 27.8927 - mae: 2.7799 - val_loss: 9.2779 - val_mae: 1.6878 - lr: 2.0000e-05\n",
      "Epoch 40/50\n",
      "125000/125000 [==============================] - 515s 4ms/step - loss: 27.8416 - mae: 2.7790 - val_loss: 7.6771 - val_mae: 1.3565 - lr: 2.0000e-05\n",
      "Epoch 41/50\n",
      "125000/125000 [==============================] - 513s 4ms/step - loss: 27.7819 - mae: 2.7773 - val_loss: 7.8785 - val_mae: 1.3811 - lr: 2.0000e-05\n",
      "Epoch 42/50\n",
      "125000/125000 [==============================] - 516s 4ms/step - loss: 27.7501 - mae: 2.7754 - val_loss: 7.6009 - val_mae: 1.2898 - lr: 2.0000e-05\n",
      "Epoch 43/50\n",
      "125000/125000 [==============================] - 514s 4ms/step - loss: 27.7170 - mae: 2.7750 - val_loss: 7.5321 - val_mae: 1.2704 - lr: 2.0000e-05\n",
      "Epoch 44/50\n",
      "125000/125000 [==============================] - 516s 4ms/step - loss: 27.6554 - mae: 2.7721 - val_loss: 7.8220 - val_mae: 1.3549 - lr: 2.0000e-05\n",
      "Epoch 45/50\n",
      "125000/125000 [==============================] - 513s 4ms/step - loss: 27.5976 - mae: 2.7708 - val_loss: 8.4549 - val_mae: 1.5816 - lr: 2.0000e-05\n",
      "Epoch 46/50\n",
      "125000/125000 [==============================] - 516s 4ms/step - loss: 27.5646 - mae: 2.7698 - val_loss: 8.0813 - val_mae: 1.4120 - lr: 2.0000e-05\n",
      "Epoch 47/50\n",
      "125000/125000 [==============================] - 514s 4ms/step - loss: 27.4819 - mae: 2.7676 - val_loss: 7.2268 - val_mae: 1.2464 - lr: 2.0000e-05\n",
      "Epoch 48/50\n",
      "125000/125000 [==============================] - 516s 4ms/step - loss: 27.4375 - mae: 2.7659 - val_loss: 8.1177 - val_mae: 1.4707 - lr: 2.0000e-05\n",
      "Epoch 49/50\n",
      "125000/125000 [==============================] - 515s 4ms/step - loss: 27.4329 - mae: 2.7645 - val_loss: 6.8832 - val_mae: 1.1976 - lr: 2.0000e-05\n",
      "Epoch 50/50\n",
      "125000/125000 [==============================] - 517s 4ms/step - loss: 27.3917 - mae: 2.7629 - val_loss: 7.0050 - val_mae: 1.2499 - lr: 2.0000e-05\n",
      "250000/250000 [==============================] - 430s 2ms/step - loss: 7.0050 - mae: 1.2499\n",
      "Epoch 1/50\n",
      "125000/125000 [==============================] - 518s 4ms/step - loss: 27.6861 - mae: 2.7676 - val_loss: 6.0827 - val_mae: 1.2729 - lr: 2.0000e-05\n",
      "Epoch 2/50\n",
      "125000/125000 [==============================] - 515s 4ms/step - loss: 27.5009 - mae: 2.7636 - val_loss: 5.9707 - val_mae: 1.2167 - lr: 2.0000e-05\n",
      "Epoch 3/50\n",
      "125000/125000 [==============================] - 519s 4ms/step - loss: 27.5259 - mae: 2.7648 - val_loss: 6.0731 - val_mae: 1.2479 - lr: 2.0000e-05\n",
      "Epoch 4/50\n",
      "125000/125000 [==============================] - 515s 4ms/step - loss: 27.5106 - mae: 2.7626 - val_loss: 6.2803 - val_mae: 1.2975 - lr: 2.0000e-05\n",
      "Epoch 5/50\n",
      "125000/125000 [==============================] - 515s 4ms/step - loss: 27.4235 - mae: 2.7611 - val_loss: 7.3205 - val_mae: 1.4172 - lr: 2.0000e-05\n",
      "Epoch 6/50\n",
      "125000/125000 [==============================] - 517s 4ms/step - loss: 27.3825 - mae: 2.7596 - val_loss: 6.4898 - val_mae: 1.3712 - lr: 2.0000e-05\n",
      "Epoch 7/50\n",
      "125000/125000 [==============================] - 517s 4ms/step - loss: 27.3312 - mae: 2.7586 - val_loss: 6.4016 - val_mae: 1.3408 - lr: 2.0000e-05\n",
      "Epoch 8/50\n",
      "125000/125000 [==============================] - 515s 4ms/step - loss: 26.4181 - mae: 2.6823 - val_loss: 5.3386 - val_mae: 1.1259 - lr: 1.0000e-05\n",
      "Epoch 9/50\n",
      "125000/125000 [==============================] - 520s 4ms/step - loss: 26.3030 - mae: 2.6787 - val_loss: 5.4239 - val_mae: 1.1511 - lr: 1.0000e-05\n",
      "Epoch 10/50\n",
      "125000/125000 [==============================] - 657s 5ms/step - loss: 26.3011 - mae: 2.6773 - val_loss: 5.2732 - val_mae: 1.1101 - lr: 1.0000e-05\n",
      "Epoch 11/50\n",
      "125000/125000 [==============================] - 762s 6ms/step - loss: 26.1925 - mae: 2.6750 - val_loss: 5.5984 - val_mae: 1.1459 - lr: 1.0000e-05\n",
      "Epoch 12/50\n",
      "125000/125000 [==============================] - 733s 6ms/step - loss: 26.2363 - mae: 2.6746 - val_loss: 5.2816 - val_mae: 1.1125 - lr: 1.0000e-05\n",
      "Epoch 13/50\n",
      "125000/125000 [==============================] - 583s 5ms/step - loss: 26.2195 - mae: 2.6750 - val_loss: 5.8888 - val_mae: 1.1913 - lr: 1.0000e-05\n",
      "Epoch 14/50\n",
      "125000/125000 [==============================] - 661s 5ms/step - loss: 26.1862 - mae: 2.6736 - val_loss: 5.3364 - val_mae: 1.1481 - lr: 1.0000e-05\n",
      "Epoch 15/50\n",
      "125000/125000 [==============================] - 618s 5ms/step - loss: 26.1616 - mae: 2.6738 - val_loss: 5.6212 - val_mae: 1.2084 - lr: 1.0000e-05\n",
      "Epoch 16/50\n",
      "125000/125000 [==============================] - 721s 6ms/step - loss: 26.0989 - mae: 2.6725 - val_loss: 5.3545 - val_mae: 1.1515 - lr: 1.0000e-05\n",
      "Epoch 17/50\n",
      "125000/125000 [==============================] - 595s 5ms/step - loss: 26.0493 - mae: 2.6714 - val_loss: 5.5846 - val_mae: 1.2319 - lr: 1.0000e-05\n",
      "Epoch 18/50\n",
      "125000/125000 [==============================] - 550s 4ms/step - loss: 26.1052 - mae: 2.6722 - val_loss: 5.2058 - val_mae: 1.1182 - lr: 1.0000e-05\n",
      "Epoch 19/50\n",
      "125000/125000 [==============================] - 671s 5ms/step - loss: 26.0613 - mae: 2.6716 - val_loss: 5.4106 - val_mae: 1.1289 - lr: 1.0000e-05\n",
      "Epoch 20/50\n",
      "125000/125000 [==============================] - 680s 5ms/step - loss: 25.9909 - mae: 2.6703 - val_loss: 5.7062 - val_mae: 1.2066 - lr: 1.0000e-05\n",
      "Epoch 21/50\n",
      "125000/125000 [==============================] - 651s 5ms/step - loss: 25.9816 - mae: 2.6699 - val_loss: 5.3570 - val_mae: 1.1494 - lr: 1.0000e-05\n",
      "Epoch 22/50\n",
      "125000/125000 [==============================] - 751s 6ms/step - loss: 25.9286 - mae: 2.6685 - val_loss: 5.6188 - val_mae: 1.2205 - lr: 1.0000e-05\n",
      "Epoch 23/50\n",
      "125000/125000 [==============================] - 750s 6ms/step - loss: 26.0041 - mae: 2.6700 - val_loss: 6.6598 - val_mae: 1.4722 - lr: 1.0000e-05\n",
      "Epoch 24/50\n",
      "125000/125000 [==============================] - 758s 6ms/step - loss: 25.9514 - mae: 2.6691 - val_loss: 5.4732 - val_mae: 1.1609 - lr: 1.0000e-05\n",
      "Epoch 25/50\n",
      "125000/125000 [==============================] - 756s 6ms/step - loss: 25.9204 - mae: 2.6690 - val_loss: 5.2891 - val_mae: 1.1545 - lr: 1.0000e-05\n",
      "Epoch 26/50\n",
      "125000/125000 [==============================] - 522s 4ms/step - loss: 25.8428 - mae: 2.6670 - val_loss: 5.3500 - val_mae: 1.1595 - lr: 1.0000e-05\n",
      "Epoch 27/50\n",
      "125000/125000 [==============================] - 518s 4ms/step - loss: 25.9048 - mae: 2.6671 - val_loss: 5.8454 - val_mae: 1.2768 - lr: 1.0000e-05\n",
      "Epoch 28/50\n",
      "125000/125000 [==============================] - 521s 4ms/step - loss: 25.8850 - mae: 2.6669 - val_loss: 5.3380 - val_mae: 1.1840 - lr: 1.0000e-05\n",
      "250000/250000 [==============================] - 434s 2ms/step - loss: 5.2059 - mae: 1.1182\n",
      "Epoch 1/50\n",
      "125000/125000 [==============================] - 528s 4ms/step - loss: 26.1319 - mae: 2.6737 - val_loss: 5.1554 - val_mae: 1.1550 - lr: 1.0000e-05\n",
      "Epoch 2/50\n",
      "125000/125000 [==============================] - 522s 4ms/step - loss: 26.0687 - mae: 2.6718 - val_loss: 5.1619 - val_mae: 1.1648 - lr: 1.0000e-05\n",
      "Epoch 3/50\n",
      "125000/125000 [==============================] - 523s 4ms/step - loss: 26.0978 - mae: 2.6726 - val_loss: 5.7441 - val_mae: 1.3542 - lr: 1.0000e-05\n",
      "Epoch 4/50\n",
      "125000/125000 [==============================] - 522s 4ms/step - loss: 26.0151 - mae: 2.6697 - val_loss: 5.2275 - val_mae: 1.1969 - lr: 1.0000e-05\n",
      "Epoch 5/50\n",
      "125000/125000 [==============================] - 525s 4ms/step - loss: 26.0728 - mae: 2.6711 - val_loss: 4.9528 - val_mae: 1.1184 - lr: 1.0000e-05\n",
      "Epoch 6/50\n",
      "125000/125000 [==============================] - 520s 4ms/step - loss: 26.0689 - mae: 2.6707 - val_loss: 5.5111 - val_mae: 1.2525 - lr: 1.0000e-05\n",
      "Epoch 7/50\n",
      "125000/125000 [==============================] - 521s 4ms/step - loss: 26.0252 - mae: 2.6701 - val_loss: 4.9808 - val_mae: 1.1190 - lr: 1.0000e-05\n",
      "Epoch 8/50\n",
      "125000/125000 [==============================] - 519s 4ms/step - loss: 25.9565 - mae: 2.6676 - val_loss: 5.3554 - val_mae: 1.2268 - lr: 1.0000e-05\n",
      "Epoch 9/50\n",
      "125000/125000 [==============================] - 521s 4ms/step - loss: 25.9200 - mae: 2.6687 - val_loss: 4.8961 - val_mae: 1.1072 - lr: 1.0000e-05\n",
      "Epoch 10/50\n",
      "125000/125000 [==============================] - 519s 4ms/step - loss: 25.9279 - mae: 2.6675 - val_loss: 5.0199 - val_mae: 1.1275 - lr: 1.0000e-05\n",
      "Epoch 11/50\n",
      "125000/125000 [==============================] - 522s 4ms/step - loss: 25.9166 - mae: 2.6674 - val_loss: 5.5581 - val_mae: 1.2908 - lr: 1.0000e-05\n",
      "Epoch 12/50\n",
      "125000/125000 [==============================] - 521s 4ms/step - loss: 25.8898 - mae: 2.6676 - val_loss: 5.1433 - val_mae: 1.1400 - lr: 1.0000e-05\n",
      "Epoch 13/50\n",
      "125000/125000 [==============================] - 521s 4ms/step - loss: 25.8705 - mae: 2.6660 - val_loss: 5.2531 - val_mae: 1.1220 - lr: 1.0000e-05\n",
      "Epoch 14/50\n",
      "125000/125000 [==============================] - 520s 4ms/step - loss: 25.8632 - mae: 2.6657 - val_loss: 5.3910 - val_mae: 1.2069 - lr: 1.0000e-05\n",
      "Epoch 15/50\n",
      "125000/125000 [==============================] - 522s 4ms/step - loss: 25.8400 - mae: 2.6652 - val_loss: 5.5837 - val_mae: 1.2835 - lr: 1.0000e-05\n",
      "Epoch 16/50\n",
      "125000/125000 [==============================] - 523s 4ms/step - loss: 25.8506 - mae: 2.6652 - val_loss: 5.3293 - val_mae: 1.1457 - lr: 1.0000e-05\n",
      "Epoch 17/50\n",
      "125000/125000 [==============================] - 520s 4ms/step - loss: 25.8133 - mae: 2.6644 - val_loss: 5.2136 - val_mae: 1.1881 - lr: 1.0000e-05\n",
      "Epoch 18/50\n",
      "125000/125000 [==============================] - 521s 4ms/step - loss: 25.8400 - mae: 2.6645 - val_loss: 5.8635 - val_mae: 1.3683 - lr: 1.0000e-05\n",
      "Epoch 19/50\n",
      "125000/125000 [==============================] - 523s 4ms/step - loss: 25.7511 - mae: 2.6629 - val_loss: 5.0617 - val_mae: 1.1153 - lr: 1.0000e-05\n",
      "250000/250000 [==============================] - 433s 2ms/step - loss: 4.8961 - mae: 1.1072\n",
      "Epoch 1/50\n",
      "125000/125000 [==============================] - 525s 4ms/step - loss: 25.9954 - mae: 2.6688 - val_loss: 4.7285 - val_mae: 1.1210 - lr: 1.0000e-05\n",
      "Epoch 2/50\n",
      "125000/125000 [==============================] - 521s 4ms/step - loss: 26.0153 - mae: 2.6693 - val_loss: 5.3961 - val_mae: 1.3016 - lr: 1.0000e-05\n",
      "Epoch 3/50\n",
      "125000/125000 [==============================] - 520s 4ms/step - loss: 25.9466 - mae: 2.6674 - val_loss: 5.1855 - val_mae: 1.1361 - lr: 1.0000e-05\n",
      "Epoch 4/50\n",
      "125000/125000 [==============================] - 521s 4ms/step - loss: 25.9088 - mae: 2.6671 - val_loss: 4.7518 - val_mae: 1.1083 - lr: 1.0000e-05\n",
      "Epoch 5/50\n",
      "125000/125000 [==============================] - 520s 4ms/step - loss: 25.8864 - mae: 2.6665 - val_loss: 4.9487 - val_mae: 1.1321 - lr: 1.0000e-05\n",
      "Epoch 6/50\n",
      "125000/125000 [==============================] - 520s 4ms/step - loss: 25.8976 - mae: 2.6665 - val_loss: 4.8809 - val_mae: 1.1484 - lr: 1.0000e-05\n",
      "Epoch 7/50\n",
      "125000/125000 [==============================] - 522s 4ms/step - loss: 25.9290 - mae: 2.6669 - val_loss: 5.2860 - val_mae: 1.1971 - lr: 1.0000e-05\n",
      "Epoch 8/50\n",
      "125000/125000 [==============================] - 520s 4ms/step - loss: 25.8716 - mae: 2.6648 - val_loss: 4.7525 - val_mae: 1.1018 - lr: 1.0000e-05\n",
      "Epoch 9/50\n",
      "125000/125000 [==============================] - 521s 4ms/step - loss: 25.8228 - mae: 2.6651 - val_loss: 4.8906 - val_mae: 1.1124 - lr: 1.0000e-05\n",
      "Epoch 10/50\n",
      "125000/125000 [==============================] - 522s 4ms/step - loss: 25.9021 - mae: 2.6655 - val_loss: 5.1334 - val_mae: 1.1344 - lr: 1.0000e-05\n",
      "Epoch 11/50\n",
      "125000/125000 [==============================] - 522s 4ms/step - loss: 25.7661 - mae: 2.6633 - val_loss: 5.0816 - val_mae: 1.2069 - lr: 1.0000e-05\n",
      "250000/250000 [==============================] - 436s 2ms/step - loss: 4.7285 - mae: 1.1210\n",
      "Epoch 1/50\n",
      "125000/125000 [==============================] - 524s 4ms/step - loss: 25.9848 - mae: 2.6687 - val_loss: 4.9864 - val_mae: 1.1188 - lr: 1.0000e-05\n",
      "Epoch 2/50\n",
      "125000/125000 [==============================] - 521s 4ms/step - loss: 25.8988 - mae: 2.6681 - val_loss: 4.9280 - val_mae: 1.1139 - lr: 1.0000e-05\n",
      "Epoch 3/50\n",
      "125000/125000 [==============================] - 521s 4ms/step - loss: 25.8759 - mae: 2.6658 - val_loss: 5.1672 - val_mae: 1.1487 - lr: 1.0000e-05\n",
      "Epoch 4/50\n",
      "125000/125000 [==============================] - 520s 4ms/step - loss: 25.8191 - mae: 2.6648 - val_loss: 5.2332 - val_mae: 1.2092 - lr: 1.0000e-05\n",
      "Epoch 5/50\n",
      "125000/125000 [==============================] - 522s 4ms/step - loss: 25.8412 - mae: 2.6654 - val_loss: 5.1595 - val_mae: 1.1254 - lr: 1.0000e-05\n",
      "Epoch 6/50\n",
      "125000/125000 [==============================] - 519s 4ms/step - loss: 25.8379 - mae: 2.6655 - val_loss: 5.0273 - val_mae: 1.1501 - lr: 1.0000e-05\n",
      "Epoch 7/50\n",
      "125000/125000 [==============================] - 519s 4ms/step - loss: 25.7938 - mae: 2.6638 - val_loss: 5.2880 - val_mae: 1.2343 - lr: 1.0000e-05\n",
      "Epoch 8/50\n",
      "125000/125000 [==============================] - 519s 4ms/step - loss: 25.7502 - mae: 2.6623 - val_loss: 5.1374 - val_mae: 1.1715 - lr: 1.0000e-05\n",
      "Epoch 9/50\n",
      "125000/125000 [==============================] - 519s 4ms/step - loss: 25.8109 - mae: 2.6633 - val_loss: 5.1550 - val_mae: 1.1499 - lr: 1.0000e-05\n",
      "Epoch 10/50\n",
      "125000/125000 [==============================] - 519s 4ms/step - loss: 25.7164 - mae: 2.6611 - val_loss: 5.0647 - val_mae: 1.1415 - lr: 1.0000e-05\n",
      "Epoch 11/50\n",
      "125000/125000 [==============================] - 519s 4ms/step - loss: 25.7770 - mae: 2.6634 - val_loss: 6.5933 - val_mae: 1.5756 - lr: 1.0000e-05\n",
      "Epoch 12/50\n",
      "125000/125000 [==============================] - 524s 4ms/step - loss: 25.7109 - mae: 2.6617 - val_loss: 5.1759 - val_mae: 1.2054 - lr: 1.0000e-05\n",
      "250000/250000 [==============================] - 435s 2ms/step - loss: 4.9280 - mae: 1.1139\n",
      "Fold results: [[7.004970073699951, 1.249872088432312], [5.20585823059082, 1.1182217597961426], [4.896093845367432, 1.107180118560791], [4.728497505187988, 1.120983362197876], [4.927961349487305, 1.1139322519302368]]\n",
      "Average result: [5.3526762  1.14203792]\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list for storing results and a KFold object for 5-fold cross-validation\n",
    "results = []\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "# Cross-validation to evaluate model\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    reset_keras()\n",
    "    history = model.fit(X_train.reshape(-1, 9, 7, 1), y_train, epochs=50, batch_size=256, validation_data=(X_test.reshape(-1, 9, 7, 1), y_test), callbacks=[reduce_lr, early_stopping, checkpoint, tensorboard_callback])\n",
    "    reset_keras()\n",
    "    results.append(model.evaluate(X_test.reshape(-1, 9, 7, 1), y_test))\n",
    "\n",
    "# Output the results of cross-validation\n",
    "print(\"Fold results:\", results)\n",
    "print(\"Average result:\", numpy.mean(results, axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
