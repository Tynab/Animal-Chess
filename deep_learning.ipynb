{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yamia\\AppData\\Local\\Temp\\ipykernel_9356\\217575311.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\yamia\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import os\n",
    "import pandas\n",
    "import tensorflow\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.regularizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.15.0\n",
      "GPU: []\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow:\", tensorflow.__version__)\n",
    "print(\"GPU:\", tensorflow.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tensorflow.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tensorflow.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        tensorflow.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_csv('animal_chess.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "board     ----r-E-Tl-----WC--d---------p------L--R--P---...\n",
       "side                                                     -1\n",
       "piece                                                     L\n",
       "atk                                                       0\n",
       "move                                                   F1E1\n",
       "river                                                     0\n",
       "trap                                                      1\n",
       "den                                                       0\n",
       "score                                                   -90\n",
       "winner                                                    0\n",
       "Name: 32, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = df.iloc[32]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode the piece\n",
    "def encode_piece(piece_char):\n",
    "    piece_mapping = {'-': 0, 'r': 1, 'c': 2, 'd': 3, 'w': 4, 'p': 5, 't': 6, 'l': 7, 'e': 8, 'R': -1, 'C': -2, 'D': -3, 'W': -4, 'P': -5, 'T': -6, 'L': -7, 'E': -8}\n",
    "    return piece_mapping.get(piece_char, 0)\n",
    "\n",
    "encode_piece(sample['piece'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  7.,  0.,  0., -7.,  0.,  0.],\n",
       "       [ 0.,  0.,  3.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  5.,  0.,  0.,  4.],\n",
       "       [ 0.,  0.,  0.,  0., -1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [-8., -4.,  0.,  0., -5.,  0.,  0.],\n",
       "       [ 0., -2.,  0.,  0.,  0., -3.,  0.],\n",
       "       [-6.,  0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode the board\n",
    "def encode_board(board_str):\n",
    "    board_matrix = numpy.zeros((9, 7))\n",
    "    for i, piece in enumerate(board_str[::-1]):\n",
    "        row, col = divmod(i, 9)\n",
    "        board_matrix[col][row] = encode_piece(piece)\n",
    "    return numpy.flip(numpy.flip(board_matrix, 0), 1)\n",
    "\n",
    "encode_board(sample['board'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.,  0.,  0., ...,  0.,  0., -7.],\n",
       "       [ 7.,  0.,  0., ...,  0.,  0., -7.],\n",
       "       [ 7.,  0.,  0., ...,  0.,  0., -7.],\n",
       "       ...,\n",
       "       [ 7.,  0.,  0., ...,  0.,  0., -7.],\n",
       "       [ 7.,  0.,  0., ...,  0.,  0., -7.],\n",
       "       [ 7.,  0.,  0., ...,  0.,  0., -7.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['board_encoded'] = df['board'].apply(encode_board)\n",
    "board_matrix_flattened = numpy.array(df['board_encoded'].tolist()).reshape(count, -1)\n",
    "board_matrix_flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = numpy.array(df['board_encoded'].tolist()).reshape(count, -1)\n",
    "y = df['score'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "313/313 [==============================] - 9s 26ms/step - loss: 8657.2725 - mae: 38.9233 - val_loss: 6810.3110 - val_mae: 33.6431 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 3935.9917 - mae: 26.8483 - val_loss: 3118.7195 - val_mae: 24.1648 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 9s 29ms/step - loss: 2109.3442 - mae: 22.9798 - val_loss: 2032.2216 - val_mae: 23.5548 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 1447.5656 - mae: 20.5345 - val_loss: 1590.6737 - val_mae: 23.0478 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 1140.1051 - mae: 18.5525 - val_loss: 1872.1396 - val_mae: 31.0715 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 18s 56ms/step - loss: 966.5275 - mae: 17.2466 - val_loss: 1007.5986 - val_mae: 15.9031 - lr: 1.0000e-04\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 862.7779 - mae: 16.1736 - val_loss: 929.4598 - val_mae: 15.8721 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 27s 85ms/step - loss: 783.3961 - mae: 15.1652 - val_loss: 868.9081 - val_mae: 15.2101 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 728.8630 - mae: 14.6931 - val_loss: 1454.0699 - val_mae: 28.2388 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 673.2368 - mae: 13.6613 - val_loss: 763.5597 - val_mae: 13.6479 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 20s 63ms/step - loss: 651.9177 - mae: 13.5128 - val_loss: 854.5587 - val_mae: 17.0192 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 620.7610 - mae: 13.1166 - val_loss: 718.1778 - val_mae: 13.5659 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 607.6896 - mae: 12.9316 - val_loss: 680.0637 - val_mae: 12.5488 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 590.5712 - mae: 12.7618 - val_loss: 689.1227 - val_mae: 13.2832 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 8s 27ms/step - loss: 554.1282 - mae: 12.1477 - val_loss: 660.1838 - val_mae: 12.7835 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 16s 51ms/step - loss: 545.7437 - mae: 11.9594 - val_loss: 682.2258 - val_mae: 13.3635 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 539.6732 - mae: 11.9191 - val_loss: 628.3892 - val_mae: 12.0683 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 516.5026 - mae: 11.4521 - val_loss: 616.2269 - val_mae: 11.6047 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 13s 43ms/step - loss: 508.4295 - mae: 11.4551 - val_loss: 688.7352 - val_mae: 14.7370 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 23s 75ms/step - loss: 485.3214 - mae: 11.0551 - val_loss: 596.3099 - val_mae: 11.3477 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 479.8672 - mae: 11.0521 - val_loss: 619.9852 - val_mae: 12.2481 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 485.9633 - mae: 11.2861 - val_loss: 638.4836 - val_mae: 13.1434 - lr: 1.0000e-04\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 459.6859 - mae: 10.7608 - val_loss: 683.3455 - val_mae: 14.8558 - lr: 1.0000e-04\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 461.6683 - mae: 10.9284 - val_loss: 563.8749 - val_mae: 11.2504 - lr: 1.0000e-04\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 16s 52ms/step - loss: 450.0297 - mae: 10.8711 - val_loss: 627.7787 - val_mae: 13.3897 - lr: 1.0000e-04\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 31s 98ms/step - loss: 437.5804 - mae: 10.5215 - val_loss: 586.9752 - val_mae: 12.4002 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 15s 48ms/step - loss: 441.9181 - mae: 10.7177 - val_loss: 822.6522 - val_mae: 19.0895 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 21s 67ms/step - loss: 419.8885 - mae: 10.1844 - val_loss: 561.8773 - val_mae: 12.2316 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 16s 50ms/step - loss: 407.3966 - mae: 10.0909 - val_loss: 538.0621 - val_mae: 11.1911 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 395.4451 - mae: 9.8127 - val_loss: 531.4369 - val_mae: 11.4311 - lr: 1.0000e-04\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 26s 82ms/step - loss: 410.1462 - mae: 10.3478 - val_loss: 648.9116 - val_mae: 14.7532 - lr: 1.0000e-04\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 22s 72ms/step - loss: 393.1102 - mae: 10.0001 - val_loss: 613.9388 - val_mae: 14.0130 - lr: 1.0000e-04\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 390.5380 - mae: 9.8382 - val_loss: 532.6980 - val_mae: 11.4076 - lr: 1.0000e-04\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 17s 55ms/step - loss: 383.6886 - mae: 9.8690 - val_loss: 645.6166 - val_mae: 15.1715 - lr: 1.0000e-04\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 13s 42ms/step - loss: 376.5671 - mae: 9.5453 - val_loss: 507.6505 - val_mae: 10.9712 - lr: 1.0000e-04\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 365.3727 - mae: 9.4072 - val_loss: 541.0816 - val_mae: 12.0649 - lr: 1.0000e-04\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 376.4468 - mae: 9.8797 - val_loss: 534.6272 - val_mae: 11.6395 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 355.1178 - mae: 9.5143 - val_loss: 551.5925 - val_mae: 12.8211 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 345.3691 - mae: 9.2336 - val_loss: 522.6154 - val_mae: 11.8005 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 356.5674 - mae: 9.6537 - val_loss: 504.3415 - val_mae: 11.1492 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 338.2516 - mae: 9.2744 - val_loss: 492.2284 - val_mae: 10.7127 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 26s 85ms/step - loss: 327.8412 - mae: 8.8903 - val_loss: 609.5587 - val_mae: 14.9690 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 31s 100ms/step - loss: 325.9267 - mae: 9.1080 - val_loss: 476.2859 - val_mae: 10.6996 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 10s 32ms/step - loss: 329.2465 - mae: 9.2644 - val_loss: 462.9247 - val_mae: 10.0942 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 324.5921 - mae: 9.2130 - val_loss: 471.3784 - val_mae: 10.6786 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 19s 62ms/step - loss: 324.0645 - mae: 9.2579 - val_loss: 480.1634 - val_mae: 10.5947 - lr: 1.0000e-04\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 29s 94ms/step - loss: 315.7848 - mae: 8.9658 - val_loss: 534.1826 - val_mae: 12.9527 - lr: 1.0000e-04\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 306.0463 - mae: 8.8366 - val_loss: 470.2038 - val_mae: 10.5285 - lr: 1.0000e-04\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 31s 100ms/step - loss: 298.7569 - mae: 8.7509 - val_loss: 468.3293 - val_mae: 10.6479 - lr: 1.0000e-04\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 31s 101ms/step - loss: 265.6921 - mae: 7.6936 - val_loss: 444.7392 - val_mae: 10.0939 - lr: 2.0000e-05\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 444.7391 - mae: 10.0939\n",
      "Epoch 1/50\n",
      "313/313 [==============================] - 33s 104ms/step - loss: 305.6164 - mae: 8.2951 - val_loss: 220.6510 - val_mae: 5.7768 - lr: 2.0000e-05\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 298.5782 - mae: 8.1922 - val_loss: 258.4734 - val_mae: 8.0912 - lr: 2.0000e-05\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 17s 53ms/step - loss: 289.8876 - mae: 8.1238 - val_loss: 226.2361 - val_mae: 5.8662 - lr: 2.0000e-05\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 285.4057 - mae: 8.0542 - val_loss: 229.8284 - val_mae: 5.9526 - lr: 2.0000e-05\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 31s 100ms/step - loss: 282.7711 - mae: 8.0093 - val_loss: 234.6417 - val_mae: 6.2188 - lr: 2.0000e-05\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 31s 98ms/step - loss: 280.9951 - mae: 8.0410 - val_loss: 231.6472 - val_mae: 5.8854 - lr: 2.0000e-05\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 31s 98ms/step - loss: 274.2977 - mae: 7.8177 - val_loss: 233.9776 - val_mae: 6.1481 - lr: 1.0000e-05\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 32s 101ms/step - loss: 272.0889 - mae: 7.7965 - val_loss: 239.3468 - val_mae: 6.4240 - lr: 1.0000e-05\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 32s 102ms/step - loss: 267.6375 - mae: 7.8019 - val_loss: 232.7034 - val_mae: 5.9644 - lr: 1.0000e-05\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 32s 102ms/step - loss: 266.4161 - mae: 7.7990 - val_loss: 234.5683 - val_mae: 6.0991 - lr: 1.0000e-05\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 30s 97ms/step - loss: 262.9542 - mae: 7.7651 - val_loss: 235.7809 - val_mae: 6.1801 - lr: 1.0000e-05\n",
      "625/625 [==============================] - 6s 9ms/step - loss: 220.6511 - mae: 5.7768\n",
      "Epoch 1/50\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 288.2922 - mae: 8.0406 - val_loss: 248.8338 - val_mae: 6.4684 - lr: 1.0000e-05\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 282.6028 - mae: 7.8899 - val_loss: 235.5361 - val_mae: 5.4479 - lr: 1.0000e-05\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 276.6748 - mae: 7.9881 - val_loss: 237.0608 - val_mae: 5.4593 - lr: 1.0000e-05\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 280.7528 - mae: 7.8916 - val_loss: 240.4321 - val_mae: 5.6663 - lr: 1.0000e-05\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 20s 62ms/step - loss: 275.0588 - mae: 7.9255 - val_loss: 260.6281 - val_mae: 6.8573 - lr: 1.0000e-05\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 270.6244 - mae: 7.9339 - val_loss: 243.3709 - val_mae: 5.7023 - lr: 1.0000e-05\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 271.1331 - mae: 7.8791 - val_loss: 246.4003 - val_mae: 5.8342 - lr: 1.0000e-05\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 270.1234 - mae: 7.8246 - val_loss: 249.6295 - val_mae: 5.9647 - lr: 1.0000e-05\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 275.2690 - mae: 7.8339 - val_loss: 259.8248 - val_mae: 6.7293 - lr: 1.0000e-05\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 265.3448 - mae: 7.8198 - val_loss: 248.8320 - val_mae: 5.9028 - lr: 1.0000e-05\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 9s 29ms/step - loss: 258.0076 - mae: 7.7649 - val_loss: 262.1507 - val_mae: 6.7634 - lr: 1.0000e-05\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 264.8188 - mae: 7.7992 - val_loss: 249.9506 - val_mae: 5.9476 - lr: 1.0000e-05\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 235.5361 - mae: 5.4479\n",
      "Epoch 1/50\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 297.6593 - mae: 8.0764 - val_loss: 174.9365 - val_mae: 5.9370 - lr: 1.0000e-05\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 297.3236 - mae: 8.0551 - val_loss: 177.6621 - val_mae: 5.9637 - lr: 1.0000e-05\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 293.4247 - mae: 8.0408 - val_loss: 170.9378 - val_mae: 5.4273 - lr: 1.0000e-05\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 9s 29ms/step - loss: 293.4705 - mae: 8.0587 - val_loss: 172.8625 - val_mae: 5.4856 - lr: 1.0000e-05\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 13s 40ms/step - loss: 286.2911 - mae: 7.8710 - val_loss: 174.7931 - val_mae: 5.5859 - lr: 1.0000e-05\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 287.9359 - mae: 7.9600 - val_loss: 176.7724 - val_mae: 5.6171 - lr: 1.0000e-05\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 16s 50ms/step - loss: 281.5789 - mae: 7.9074 - val_loss: 179.4278 - val_mae: 5.8124 - lr: 1.0000e-05\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 31s 99ms/step - loss: 284.1693 - mae: 7.9099 - val_loss: 186.4600 - val_mae: 6.1899 - lr: 1.0000e-05\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 23s 75ms/step - loss: 284.5791 - mae: 7.8556 - val_loss: 180.8681 - val_mae: 5.7332 - lr: 1.0000e-05\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 280.4053 - mae: 7.9492 - val_loss: 178.7565 - val_mae: 5.6726 - lr: 1.0000e-05\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 278.3157 - mae: 7.7842 - val_loss: 187.6887 - val_mae: 6.1963 - lr: 1.0000e-05\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 282.5449 - mae: 7.9741 - val_loss: 214.8153 - val_mae: 7.8777 - lr: 1.0000e-05\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 281.2553 - mae: 7.8865 - val_loss: 196.4868 - val_mae: 6.7147 - lr: 1.0000e-05\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 170.9377 - mae: 5.4273\n",
      "Epoch 1/50\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 293.0289 - mae: 8.0856 - val_loss: 168.2453 - val_mae: 5.2116 - lr: 1.0000e-05\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 285.7589 - mae: 7.9439 - val_loss: 171.8241 - val_mae: 5.4723 - lr: 1.0000e-05\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 16s 53ms/step - loss: 284.1289 - mae: 7.9260 - val_loss: 175.8617 - val_mae: 5.5893 - lr: 1.0000e-05\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 283.5559 - mae: 7.9513 - val_loss: 180.7554 - val_mae: 5.8114 - lr: 1.0000e-05\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 28s 88ms/step - loss: 283.4896 - mae: 7.9309 - val_loss: 178.6885 - val_mae: 5.5595 - lr: 1.0000e-05\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 280.0382 - mae: 7.8398 - val_loss: 178.4338 - val_mae: 5.5977 - lr: 1.0000e-05\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 282.0204 - mae: 7.8718 - val_loss: 182.4936 - val_mae: 5.9271 - lr: 1.0000e-05\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 281.8560 - mae: 7.8368 - val_loss: 178.1400 - val_mae: 5.5487 - lr: 1.0000e-05\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 274.1010 - mae: 7.8293 - val_loss: 183.1494 - val_mae: 5.9370 - lr: 1.0000e-05\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 275.1306 - mae: 7.7762 - val_loss: 189.4128 - val_mae: 6.2055 - lr: 1.0000e-05\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 275.4671 - mae: 7.8507 - val_loss: 184.6688 - val_mae: 5.8260 - lr: 1.0000e-05\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 168.2453 - mae: 5.2116\n",
      "Fold results: [[444.7391357421875, 10.093870162963867], [220.65109252929688, 5.776752948760986], [235.53611755371094, 5.4478583335876465], [170.93771362304688, 5.42732572555542], [168.24526977539062, 5.211616516113281]]\n",
      "Average result: [248.02186584   6.39148474]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Định nghĩa hàm xây dựng mô hình\n",
    "def build_model(input_shape, activation='relu'):\n",
    "    model = Sequential([\n",
    "        Input(shape=input_shape),\n",
    "        Conv2D(128, (3, 3), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Activation(activation),\n",
    "        MaxPooling2D((2, 2)),\n",
    "\n",
    "        Conv2D(256, (3, 3), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Activation(activation),\n",
    "        MaxPooling2D((2, 2)),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(2048, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='linear')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='mean_squared_error', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# Tạo model mới với hàm kích hoạt là LeakyReLU\n",
    "model = build_model((9, 7, 1), activation='leaky_relu')\n",
    "\n",
    "# Log directory cho TensorBoard\n",
    "log_dir = os.path.join(\"logs\", \"fit\", datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Chuẩn bị callbacks\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint(\"best_model.h5\", monitor='val_loss', save_best_only=True, save_format='tf')\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "results = []\n",
    "kf = KFold(n_splits=5)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    history = model.fit(X_train.reshape(-1, 9, 7, 1), y_train, epochs=50, batch_size=256,\n",
    "                        validation_data=(X_test.reshape(-1, 9, 7, 1), y_test),\n",
    "                        callbacks=[reduce_lr, early_stopping, checkpoint, tensorboard_callback])\n",
    "\n",
    "    results.append(model.evaluate(X_test.reshape(-1, 9, 7, 1), y_test))\n",
    "\n",
    "print(\"Fold results:\", results)\n",
    "print(\"Average result:\", np.mean(results, axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
