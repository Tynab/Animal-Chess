{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy\n",
    "import os\n",
    "import pandas\n",
    "import tensorflow\n",
    "\n",
    "from datetime import *\n",
    "from sklearn.model_selection import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.regularizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set NVIDIA GeForce RTX 3060 memory limit in MB\n",
    "GPU_LIM_MB = 1_024 * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve a list of available GPUs\n",
    "gpus = tensorflow.config.list_physical_devices('GPU')\n",
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the memory limit for the first GPU\n",
    "if gpus:\n",
    "    try:\n",
    "        tensorflow.config.set_visible_devices(gpus[0], 'GPU')\n",
    "        tensorflow.config.experimental.set_virtual_device_configuration(gpus[0], [tensorflow.config.experimental.VirtualDeviceConfiguration(memory_limit=GPU_LIM_MB)])\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>board</th>\n",
       "      <th>side</th>\n",
       "      <th>piece</th>\n",
       "      <th>atk</th>\n",
       "      <th>move</th>\n",
       "      <th>river</th>\n",
       "      <th>trap</th>\n",
       "      <th>den</th>\n",
       "      <th>score</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l-r---ET--d-----C---p---W-------------w---P---...</td>\n",
       "      <td>-1</td>\n",
       "      <td>T</td>\n",
       "      <td>6</td>\n",
       "      <td>A9A8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l--r--ET--d-----C---p---W-------------w---P---...</td>\n",
       "      <td>1</td>\n",
       "      <td>r</td>\n",
       "      <td>1</td>\n",
       "      <td>A3A4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>l--r--ET--d-----C---p---W-------------w---P---...</td>\n",
       "      <td>-1</td>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>G7G6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>l---r-ET--d-----C---p---W-------------w---P---...</td>\n",
       "      <td>1</td>\n",
       "      <td>r</td>\n",
       "      <td>1</td>\n",
       "      <td>A4A5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>l---r-ET--d-----C---p---W-------------w---P---...</td>\n",
       "      <td>-1</td>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>G6G5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               board  side piece  atk  move  \\\n",
       "0  l-r---ET--d-----C---p---W-------------w---P---...    -1     T    6  A9A8   \n",
       "1  l--r--ET--d-----C---p---W-------------w---P---...     1     r    1  A3A4   \n",
       "2  l--r--ET--d-----C---p---W-------------w---P---...    -1     R    1  G7G6   \n",
       "3  l---r-ET--d-----C---p---W-------------w---P---...     1     r    1  A4A5   \n",
       "4  l---r-ET--d-----C---p---W-------------w---P---...    -1     R    1  G6G5   \n",
       "\n",
       "   river  trap  den  score  winner  \n",
       "0      0     0    0      0       0  \n",
       "1      0     0    0      0       0  \n",
       "2      0     0    0      0       0  \n",
       "3      0     0    0      0       0  \n",
       "4      0     0    0      0       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = pandas.read_csv('animal_chess.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38916018"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the total number of rows\n",
    "count = len(df)\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "board     ------T---l----C---dp--------w---W-----R------...\n",
       "side                                                     -1\n",
       "piece                                                     R\n",
       "atk                                                       1\n",
       "move                                                   F4E4\n",
       "river                                                     1\n",
       "trap                                                      0\n",
       "den                                                       0\n",
       "score                                                    70\n",
       "winner                                                    0\n",
       "Name: 32, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the sample at index 32\n",
    "sample = df.iloc[32]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode chess pieces to integer\n",
    "def encode_piece(piece_char):\n",
    "    piece_mapping = {'-': 0, 'r': 1, 'c': 2, 'd': 3, 'w': 4, 'p': 5, 't': 6, 'l': 7, 'e': 8, 'R': -1, 'C': -2, 'D': -3, 'W': -4, 'P': -5, 'T': -6, 'L': -7, 'E': -8}\n",
    "    return piece_mapping.get(piece_char, 0)\n",
    "\n",
    "encode_piece(sample['piece'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  6.],\n",
       "       [ 0.,  7.,  3.,  0.,  0.,  2.,  8.],\n",
       "       [ 0.,  0.,  5.,  4.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [-6., -2.,  0., -4.,  0., -5.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0., -3.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0., -7.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode chess board to matrix\n",
    "def encode_board(board_str):\n",
    "    board_matrix = numpy.zeros((9, 7))\n",
    "    for i, piece in enumerate(board_str[::-1]):\n",
    "        row, col = divmod(i, 9)\n",
    "        board_matrix[col][row] = encode_piece(piece)\n",
    "    return numpy.flip(numpy.flip(board_matrix, 0), 1)\n",
    "\n",
    "encode_board(sample['board'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.,  0.,  0., ...,  0.,  0., -7.],\n",
       "       [ 7.,  0.,  0., ...,  0.,  0., -7.],\n",
       "       [ 7.,  0.,  0., ...,  0.,  0., -7.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode all chess boards\n",
    "df['board_encoded'] = df['board'].apply(encode_board)\n",
    "board_matrix_flattened = numpy.array(df['board_encoded'].tolist()).reshape(count, -1)\n",
    "board_matrix_flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((38916018, 63), (38916018,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare data for model training\n",
    "X = numpy.array(df['board_encoded'].tolist()).reshape(count, -1)\n",
    "y = df['score'].values\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Reset Keras session\n",
    "def reset_keras():\n",
    "    tensorflow.keras.backend.clear_session()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Build the model architecture\n",
    "def build_model(input_shape, activation='relu'):\n",
    "    # Create a sequential model\n",
    "    model = Sequential([\n",
    "        # Input layer specifies the shape of the input data\n",
    "        Input(shape=input_shape),\n",
    "        # First convolution layer with 128 filters\n",
    "        Conv2D(128, (3, 3), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Activation(activation),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        # Second convolution layer with 256 filters\n",
    "        Conv2D(256, (3, 3), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Activation(activation),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        # Flatten the output from 2D to 1D before passing to the dense layer\n",
    "        Flatten(),\n",
    "        Dense(2048, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dropout(0.5),\n",
    "        # Output layer with linear activation to predict a continuous value\n",
    "        Dense(1, activation='linear')\n",
    "    ])\n",
    "    # Compile the model with Adam optimizer and mean squared error loss\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='mean_squared_error', metrics=['mae'])\n",
    "    # Return the model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Create the neural network model with the specified input shape and activation function\n",
    "model = build_model((9, 7, 1), activation='leaky_relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Set up TensorBoard logging with a timestamped directory to monitor the training process\n",
    "log_dir = os.path.join(\"logs\", \"fit\", datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Initialize callbacks for adaptive learning rate, early stopping to prevent overfitting, and saving the best model\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint(\"best_model.h5\", monitor='val_loss', save_best_only=True, save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "121613/121613 [==============================] - 854s 7ms/step - loss: 222.2604 - mae: 7.3154 - val_loss: 82.3185 - val_mae: 3.5253 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "121613/121613 [==============================] - 847s 7ms/step - loss: 96.1741 - mae: 5.3070 - val_loss: 57.4042 - val_mae: 3.2511 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "121613/121613 [==============================] - 847s 7ms/step - loss: 75.1941 - mae: 4.7049 - val_loss: 52.9104 - val_mae: 3.3610 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "121613/121613 [==============================] - 849s 7ms/step - loss: 62.8278 - mae: 4.2775 - val_loss: 41.9617 - val_mae: 2.6994 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      "121613/121613 [==============================] - 716s 6ms/step - loss: 55.5389 - mae: 4.0097 - val_loss: 34.5697 - val_mae: 2.4679 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "121613/121613 [==============================] - 588s 5ms/step - loss: 50.6629 - mae: 3.8388 - val_loss: 34.5833 - val_mae: 2.4023 - lr: 1.0000e-04\n",
      "Epoch 7/50\n",
      "121613/121613 [==============================] - 588s 5ms/step - loss: 47.1685 - mae: 3.7198 - val_loss: 32.1934 - val_mae: 2.7439 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "121613/121613 [==============================] - 589s 5ms/step - loss: 44.7957 - mae: 3.6338 - val_loss: 30.6232 - val_mae: 2.6824 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "121613/121613 [==============================] - 588s 5ms/step - loss: 42.9877 - mae: 3.5657 - val_loss: 28.1836 - val_mae: 2.3139 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "121613/121613 [==============================] - 588s 5ms/step - loss: 40.8105 - mae: 3.4999 - val_loss: 36.1180 - val_mae: 3.6978 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "121613/121613 [==============================] - 589s 5ms/step - loss: 39.8696 - mae: 3.4558 - val_loss: 26.5406 - val_mae: 2.4608 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "121613/121613 [==============================] - 589s 5ms/step - loss: 38.2887 - mae: 3.4059 - val_loss: 24.5659 - val_mae: 2.2132 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "121613/121613 [==============================] - 588s 5ms/step - loss: 37.2706 - mae: 3.3704 - val_loss: 27.1124 - val_mae: 2.4447 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "121613/121613 [==============================] - 589s 5ms/step - loss: 36.5101 - mae: 3.3389 - val_loss: 29.8368 - val_mae: 3.2483 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "121613/121613 [==============================] - 589s 5ms/step - loss: 35.4874 - mae: 3.3070 - val_loss: 27.5497 - val_mae: 2.7036 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "121613/121613 [==============================] - 590s 5ms/step - loss: 34.9230 - mae: 3.2807 - val_loss: 22.0119 - val_mae: 2.0835 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "121613/121613 [==============================] - 590s 5ms/step - loss: 34.2384 - mae: 3.2583 - val_loss: 25.5314 - val_mae: 2.4040 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "121613/121613 [==============================] - 589s 5ms/step - loss: 33.6879 - mae: 3.2371 - val_loss: 40.5678 - val_mae: 4.6104 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "121613/121613 [==============================] - 591s 5ms/step - loss: 33.3157 - mae: 3.2170 - val_loss: 18.8809 - val_mae: 1.9452 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "121613/121613 [==============================] - 589s 5ms/step - loss: 32.6722 - mae: 3.1984 - val_loss: 22.7628 - val_mae: 2.4157 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "121613/121613 [==============================] - 590s 5ms/step - loss: 32.2050 - mae: 3.1811 - val_loss: 19.4622 - val_mae: 1.8356 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "121613/121613 [==============================] - 590s 5ms/step - loss: 31.9073 - mae: 3.1678 - val_loss: 20.1766 - val_mae: 1.8622 - lr: 1.0000e-04\n",
      "Epoch 23/50\n",
      "121613/121613 [==============================] - 590s 5ms/step - loss: 31.6241 - mae: 3.1526 - val_loss: 26.7183 - val_mae: 2.4338 - lr: 1.0000e-04\n",
      "Epoch 24/50\n",
      "121613/121613 [==============================] - 590s 5ms/step - loss: 31.2446 - mae: 3.1425 - val_loss: 20.4659 - val_mae: 1.9087 - lr: 1.0000e-04\n",
      "Epoch 25/50\n",
      "121613/121613 [==============================] - 590s 5ms/step - loss: 24.9715 - mae: 2.7887 - val_loss: 14.4809 - val_mae: 1.6550 - lr: 2.0000e-05\n",
      "Epoch 26/50\n",
      "121613/121613 [==============================] - 593s 5ms/step - loss: 23.8178 - mae: 2.7609 - val_loss: 14.1299 - val_mae: 1.6685 - lr: 2.0000e-05\n",
      "Epoch 27/50\n",
      "121613/121613 [==============================] - 701s 6ms/step - loss: 23.4286 - mae: 2.7570 - val_loss: 14.2779 - val_mae: 1.6399 - lr: 2.0000e-05\n",
      "Epoch 28/50\n",
      "121613/121613 [==============================] - 612s 5ms/step - loss: 23.2379 - mae: 2.7541 - val_loss: 13.3835 - val_mae: 1.5486 - lr: 2.0000e-05\n",
      "Epoch 29/50\n",
      "121613/121613 [==============================] - 596s 5ms/step - loss: 23.0148 - mae: 2.7543 - val_loss: 13.4443 - val_mae: 1.5264 - lr: 2.0000e-05\n",
      "Epoch 30/50\n",
      "121613/121613 [==============================] - 590s 5ms/step - loss: 22.7544 - mae: 2.7516 - val_loss: 13.7198 - val_mae: 1.5657 - lr: 2.0000e-05\n",
      "Epoch 31/50\n",
      "121613/121613 [==============================] - 590s 5ms/step - loss: 22.5751 - mae: 2.7491 - val_loss: 13.7279 - val_mae: 1.6424 - lr: 2.0000e-05\n",
      "Epoch 32/50\n",
      "121613/121613 [==============================] - 590s 5ms/step - loss: 22.4272 - mae: 2.7492 - val_loss: 12.6228 - val_mae: 1.4843 - lr: 2.0000e-05\n",
      "Epoch 33/50\n",
      "121613/121613 [==============================] - 588s 5ms/step - loss: 22.3216 - mae: 2.7472 - val_loss: 12.5965 - val_mae: 1.4575 - lr: 2.0000e-05\n",
      "Epoch 34/50\n",
      "121613/121613 [==============================] - 589s 5ms/step - loss: 22.1434 - mae: 2.7457 - val_loss: 13.0978 - val_mae: 1.5788 - lr: 2.0000e-05\n",
      "Epoch 35/50\n",
      "121613/121613 [==============================] - 588s 5ms/step - loss: 22.1288 - mae: 2.7465 - val_loss: 13.4014 - val_mae: 1.6986 - lr: 2.0000e-05\n",
      "Epoch 36/50\n",
      "121613/121613 [==============================] - 590s 5ms/step - loss: 21.9767 - mae: 2.7440 - val_loss: 12.5751 - val_mae: 1.4827 - lr: 2.0000e-05\n",
      "Epoch 37/50\n",
      "121613/121613 [==============================] - 590s 5ms/step - loss: 21.9006 - mae: 2.7429 - val_loss: 12.7512 - val_mae: 1.5295 - lr: 2.0000e-05\n",
      "Epoch 38/50\n",
      "121613/121613 [==============================] - 587s 5ms/step - loss: 21.7732 - mae: 2.7417 - val_loss: 12.5488 - val_mae: 1.5303 - lr: 2.0000e-05\n",
      "Epoch 39/50\n",
      "121613/121613 [==============================] - 588s 5ms/step - loss: 21.7588 - mae: 2.7402 - val_loss: 12.7707 - val_mae: 1.4517 - lr: 2.0000e-05\n",
      "Epoch 40/50\n",
      "121613/121613 [==============================] - 589s 5ms/step - loss: 21.6552 - mae: 2.7391 - val_loss: 13.9192 - val_mae: 1.8224 - lr: 2.0000e-05\n",
      "Epoch 41/50\n",
      "121613/121613 [==============================] - 587s 5ms/step - loss: 21.5708 - mae: 2.7371 - val_loss: 12.7749 - val_mae: 1.5872 - lr: 2.0000e-05\n",
      "Epoch 42/50\n",
      "121613/121613 [==============================] - 588s 5ms/step - loss: 21.4723 - mae: 2.7360 - val_loss: 12.8098 - val_mae: 1.4776 - lr: 2.0000e-05\n",
      "Epoch 43/50\n",
      "121613/121613 [==============================] - 588s 5ms/step - loss: 21.3924 - mae: 2.7327 - val_loss: 12.6051 - val_mae: 1.5702 - lr: 2.0000e-05\n",
      "Epoch 44/50\n",
      "121613/121613 [==============================] - 588s 5ms/step - loss: 20.3629 - mae: 2.6594 - val_loss: 12.9101 - val_mae: 1.6254 - lr: 1.0000e-05\n",
      "Epoch 45/50\n",
      "121613/121613 [==============================] - 589s 5ms/step - loss: 20.2673 - mae: 2.6529 - val_loss: 13.2413 - val_mae: 1.7513 - lr: 1.0000e-05\n",
      "Epoch 46/50\n",
      "121613/121613 [==============================] - 589s 5ms/step - loss: 20.1955 - mae: 2.6516 - val_loss: 11.6849 - val_mae: 1.4465 - lr: 1.0000e-05\n",
      "Epoch 47/50\n",
      "121613/121613 [==============================] - 588s 5ms/step - loss: 20.1732 - mae: 2.6501 - val_loss: 12.1043 - val_mae: 1.4708 - lr: 1.0000e-05\n",
      "Epoch 48/50\n",
      "121613/121613 [==============================] - 589s 5ms/step - loss: 20.1433 - mae: 2.6502 - val_loss: 11.6340 - val_mae: 1.4277 - lr: 1.0000e-05\n",
      "Epoch 49/50\n",
      "121613/121613 [==============================] - 588s 5ms/step - loss: 20.0863 - mae: 2.6497 - val_loss: 11.5389 - val_mae: 1.3791 - lr: 1.0000e-05\n",
      "Epoch 50/50\n",
      "121613/121613 [==============================] - 589s 5ms/step - loss: 20.0041 - mae: 2.6486 - val_loss: 12.6903 - val_mae: 1.7223 - lr: 1.0000e-05\n",
      "243226/243226 [==============================] - 424s 2ms/step - loss: 12.6903 - mae: 1.7223\n",
      "Epoch 1/50\n",
      "121613/121613 [==============================] - 597s 5ms/step - loss: 21.0565 - mae: 2.6544 - val_loss: 7.6024 - val_mae: 1.4349 - lr: 1.0000e-05\n",
      "Epoch 2/50\n",
      "121613/121613 [==============================] - 593s 5ms/step - loss: 20.9429 - mae: 2.6559 - val_loss: 7.4313 - val_mae: 1.3701 - lr: 1.0000e-05\n",
      "Epoch 3/50\n",
      "121613/121613 [==============================] - 591s 5ms/step - loss: 20.8505 - mae: 2.6561 - val_loss: 7.7110 - val_mae: 1.4554 - lr: 1.0000e-05\n",
      "Epoch 4/50\n",
      "121613/121613 [==============================] - 592s 5ms/step - loss: 20.8054 - mae: 2.6560 - val_loss: 8.6923 - val_mae: 1.6396 - lr: 1.0000e-05\n",
      "Epoch 5/50\n",
      "121613/121613 [==============================] - 592s 5ms/step - loss: 20.6957 - mae: 2.6550 - val_loss: 8.0944 - val_mae: 1.5363 - lr: 1.0000e-05\n",
      "Epoch 6/50\n",
      "121613/121613 [==============================] - 591s 5ms/step - loss: 20.6163 - mae: 2.6536 - val_loss: 7.4945 - val_mae: 1.3778 - lr: 1.0000e-05\n",
      "Epoch 7/50\n",
      "121613/121613 [==============================] - 593s 5ms/step - loss: 20.5417 - mae: 2.6536 - val_loss: 7.6660 - val_mae: 1.4279 - lr: 1.0000e-05\n",
      "Epoch 8/50\n",
      "121613/121613 [==============================] - 593s 5ms/step - loss: 20.5100 - mae: 2.6534 - val_loss: 7.6653 - val_mae: 1.4242 - lr: 1.0000e-05\n",
      "Epoch 9/50\n",
      "121613/121613 [==============================] - 592s 5ms/step - loss: 20.5091 - mae: 2.6529 - val_loss: 8.8249 - val_mae: 1.6523 - lr: 1.0000e-05\n",
      "Epoch 10/50\n",
      "121613/121613 [==============================] - 593s 5ms/step - loss: 20.4431 - mae: 2.6530 - val_loss: 8.0166 - val_mae: 1.4717 - lr: 1.0000e-05\n",
      "Epoch 11/50\n",
      "121613/121613 [==============================] - 592s 5ms/step - loss: 20.3975 - mae: 2.6532 - val_loss: 7.6279 - val_mae: 1.3928 - lr: 1.0000e-05\n",
      "Epoch 12/50\n",
      "121613/121613 [==============================] - 593s 5ms/step - loss: 20.3188 - mae: 2.6505 - val_loss: 7.8245 - val_mae: 1.4745 - lr: 1.0000e-05\n",
      "243226/243226 [==============================] - 427s 2ms/step - loss: 7.4311 - mae: 1.3701\n",
      "Epoch 1/50\n",
      "121613/121613 [==============================] - 595s 5ms/step - loss: 20.8772 - mae: 2.6574 - val_loss: 7.2270 - val_mae: 1.3773 - lr: 1.0000e-05\n",
      "Epoch 2/50\n",
      "121613/121613 [==============================] - 592s 5ms/step - loss: 20.9060 - mae: 2.6571 - val_loss: 7.3681 - val_mae: 1.3864 - lr: 1.0000e-05\n",
      "Epoch 3/50\n",
      "121613/121613 [==============================] - 590s 5ms/step - loss: 20.8148 - mae: 2.6576 - val_loss: 7.3478 - val_mae: 1.3931 - lr: 1.0000e-05\n",
      "Epoch 4/50\n",
      "121613/121613 [==============================] - 591s 5ms/step - loss: 20.6825 - mae: 2.6564 - val_loss: 7.3442 - val_mae: 1.4061 - lr: 1.0000e-05\n",
      "Epoch 5/50\n",
      "121613/121613 [==============================] - 591s 5ms/step - loss: 20.6941 - mae: 2.6575 - val_loss: 8.1591 - val_mae: 1.5920 - lr: 1.0000e-05\n",
      "Epoch 6/50\n",
      "121613/121613 [==============================] - 592s 5ms/step - loss: 20.5475 - mae: 2.6556 - val_loss: 8.4514 - val_mae: 1.6464 - lr: 1.0000e-05\n",
      "Epoch 7/50\n",
      "121613/121613 [==============================] - 591s 5ms/step - loss: 20.5853 - mae: 2.6559 - val_loss: 7.9042 - val_mae: 1.4848 - lr: 1.0000e-05\n",
      "Epoch 8/50\n",
      "121613/121613 [==============================] - 591s 5ms/step - loss: 20.4996 - mae: 2.6539 - val_loss: 7.8097 - val_mae: 1.4949 - lr: 1.0000e-05\n",
      "Epoch 9/50\n",
      "121613/121613 [==============================] - 591s 5ms/step - loss: 20.4048 - mae: 2.6540 - val_loss: 8.2069 - val_mae: 1.6282 - lr: 1.0000e-05\n",
      "Epoch 10/50\n",
      "121613/121613 [==============================] - 591s 5ms/step - loss: 20.4118 - mae: 2.6546 - val_loss: 8.1792 - val_mae: 1.5826 - lr: 1.0000e-05\n",
      "Epoch 11/50\n",
      "121613/121613 [==============================] - 598s 5ms/step - loss: 20.4055 - mae: 2.6539 - val_loss: 7.4624 - val_mae: 1.4044 - lr: 1.0000e-05\n",
      "243226/243226 [==============================] - 425s 2ms/step - loss: 7.2268 - mae: 1.3773\n",
      "Epoch 1/50\n",
      "121613/121613 [==============================] - 594s 5ms/step - loss: 20.7635 - mae: 2.6555 - val_loss: 7.6745 - val_mae: 1.4299 - lr: 1.0000e-05\n",
      "Epoch 2/50\n",
      "121613/121613 [==============================] - 591s 5ms/step - loss: 20.6739 - mae: 2.6553 - val_loss: 7.5643 - val_mae: 1.4056 - lr: 1.0000e-05\n",
      "Epoch 3/50\n",
      "121613/121613 [==============================] - 591s 5ms/step - loss: 20.5380 - mae: 2.6541 - val_loss: 7.9477 - val_mae: 1.4710 - lr: 1.0000e-05\n",
      "Epoch 4/50\n",
      "121613/121613 [==============================] - 591s 5ms/step - loss: 20.5734 - mae: 2.6541 - val_loss: 7.6099 - val_mae: 1.3891 - lr: 1.0000e-05\n",
      "Epoch 5/50\n",
      "121613/121613 [==============================] - 591s 5ms/step - loss: 20.4417 - mae: 2.6531 - val_loss: 7.5218 - val_mae: 1.3776 - lr: 1.0000e-05\n",
      "Epoch 6/50\n",
      "121613/121613 [==============================] - 591s 5ms/step - loss: 20.4689 - mae: 2.6540 - val_loss: 7.7044 - val_mae: 1.3997 - lr: 1.0000e-05\n",
      "Epoch 7/50\n",
      "121613/121613 [==============================] - 590s 5ms/step - loss: 20.4594 - mae: 2.6537 - val_loss: 7.9919 - val_mae: 1.3726 - lr: 1.0000e-05\n",
      "Epoch 8/50\n",
      "121613/121613 [==============================] - 637s 5ms/step - loss: 20.3505 - mae: 2.6529 - val_loss: 8.5558 - val_mae: 1.5786 - lr: 1.0000e-05\n",
      "Epoch 9/50\n",
      "121613/121613 [==============================] - 653s 5ms/step - loss: 20.3527 - mae: 2.6533 - val_loss: 7.7798 - val_mae: 1.4036 - lr: 1.0000e-05\n",
      "Epoch 10/50\n",
      "121613/121613 [==============================] - 856s 7ms/step - loss: 20.2739 - mae: 2.6524 - val_loss: 8.5658 - val_mae: 1.5382 - lr: 1.0000e-05\n",
      "Epoch 11/50\n",
      "121613/121613 [==============================] - 893s 7ms/step - loss: 20.2364 - mae: 2.6510 - val_loss: 8.1514 - val_mae: 1.4478 - lr: 1.0000e-05\n",
      "Epoch 12/50\n",
      "121613/121613 [==============================] - 746s 6ms/step - loss: 20.1639 - mae: 2.6506 - val_loss: 9.0269 - val_mae: 1.7388 - lr: 1.0000e-05\n",
      "Epoch 13/50\n",
      "121613/121613 [==============================] - 596s 5ms/step - loss: 20.1260 - mae: 2.6509 - val_loss: 8.0203 - val_mae: 1.4776 - lr: 1.0000e-05\n",
      "Epoch 14/50\n",
      "121613/121613 [==============================] - 591s 5ms/step - loss: 20.0962 - mae: 2.6498 - val_loss: 8.0832 - val_mae: 1.4486 - lr: 1.0000e-05\n",
      "Epoch 15/50\n",
      "121613/121613 [==============================] - 591s 5ms/step - loss: 20.0517 - mae: 2.6494 - val_loss: 7.8085 - val_mae: 1.3692 - lr: 1.0000e-05\n",
      "243226/243226 [==============================] - 430s 2ms/step - loss: 7.5220 - mae: 1.3776\n",
      "Epoch 1/50\n",
      "121613/121613 [==============================] - 595s 5ms/step - loss: 20.5463 - mae: 2.6579 - val_loss: 8.1084 - val_mae: 1.6160 - lr: 1.0000e-05\n",
      "Epoch 2/50\n",
      "121613/121613 [==============================] - 590s 5ms/step - loss: 20.5174 - mae: 2.6567 - val_loss: 7.7936 - val_mae: 1.4536 - lr: 1.0000e-05\n",
      "Epoch 3/50\n",
      "121613/121613 [==============================] - 590s 5ms/step - loss: 20.4498 - mae: 2.6569 - val_loss: 7.9101 - val_mae: 1.4894 - lr: 1.0000e-05\n",
      "Epoch 4/50\n",
      "121613/121613 [==============================] - 589s 5ms/step - loss: 20.3730 - mae: 2.6557 - val_loss: 7.6991 - val_mae: 1.4480 - lr: 1.0000e-05\n",
      "Epoch 5/50\n",
      "121613/121613 [==============================] - 590s 5ms/step - loss: 20.2954 - mae: 2.6537 - val_loss: 7.7742 - val_mae: 1.4431 - lr: 1.0000e-05\n",
      "Epoch 6/50\n",
      "121613/121613 [==============================] - 592s 5ms/step - loss: 20.2438 - mae: 2.6532 - val_loss: 8.0215 - val_mae: 1.4937 - lr: 1.0000e-05\n",
      "Epoch 7/50\n",
      "121613/121613 [==============================] - 592s 5ms/step - loss: 20.2187 - mae: 2.6537 - val_loss: 8.0254 - val_mae: 1.4980 - lr: 1.0000e-05\n",
      "Epoch 8/50\n",
      "121613/121613 [==============================] - 590s 5ms/step - loss: 20.2274 - mae: 2.6522 - val_loss: 7.6035 - val_mae: 1.3911 - lr: 1.0000e-05\n",
      "Epoch 9/50\n",
      "121613/121613 [==============================] - 592s 5ms/step - loss: 20.1832 - mae: 2.6520 - val_loss: 7.7581 - val_mae: 1.4314 - lr: 1.0000e-05\n",
      "Epoch 10/50\n",
      "121613/121613 [==============================] - 591s 5ms/step - loss: 20.1473 - mae: 2.6525 - val_loss: 7.4250 - val_mae: 1.3683 - lr: 1.0000e-05\n",
      "Epoch 11/50\n",
      "121613/121613 [==============================] - 591s 5ms/step - loss: 20.0431 - mae: 2.6508 - val_loss: 7.5014 - val_mae: 1.3824 - lr: 1.0000e-05\n",
      "Epoch 12/50\n",
      "121613/121613 [==============================] - 591s 5ms/step - loss: 20.0919 - mae: 2.6510 - val_loss: 8.1241 - val_mae: 1.4627 - lr: 1.0000e-05\n",
      "Epoch 13/50\n",
      "121613/121613 [==============================] - 591s 5ms/step - loss: 20.0305 - mae: 2.6501 - val_loss: 8.2898 - val_mae: 1.5228 - lr: 1.0000e-05\n",
      "Epoch 14/50\n",
      "121613/121613 [==============================] - 590s 5ms/step - loss: 20.0003 - mae: 2.6508 - val_loss: 7.7218 - val_mae: 1.3793 - lr: 1.0000e-05\n",
      "Epoch 15/50\n",
      "121613/121613 [==============================] - 591s 5ms/step - loss: 19.8928 - mae: 2.6491 - val_loss: 7.5561 - val_mae: 1.3576 - lr: 1.0000e-05\n",
      "Epoch 16/50\n",
      "121613/121613 [==============================] - 590s 5ms/step - loss: 19.8671 - mae: 2.6477 - val_loss: 7.6264 - val_mae: 1.3862 - lr: 1.0000e-05\n",
      "Epoch 17/50\n",
      "121613/121613 [==============================] - 591s 5ms/step - loss: 19.8312 - mae: 2.6467 - val_loss: 7.8189 - val_mae: 1.3986 - lr: 1.0000e-05\n",
      "Epoch 18/50\n",
      "121613/121613 [==============================] - 591s 5ms/step - loss: 19.8992 - mae: 2.6480 - val_loss: 7.6534 - val_mae: 1.3997 - lr: 1.0000e-05\n",
      "Epoch 19/50\n",
      "121613/121613 [==============================] - 591s 5ms/step - loss: 19.8034 - mae: 2.6469 - val_loss: 8.4222 - val_mae: 1.5018 - lr: 1.0000e-05\n",
      "Epoch 20/50\n",
      "121613/121613 [==============================] - 590s 5ms/step - loss: 19.7353 - mae: 2.6464 - val_loss: 7.7329 - val_mae: 1.3646 - lr: 1.0000e-05\n",
      "243226/243226 [==============================] - 428s 2ms/step - loss: 7.4250 - mae: 1.3683\n",
      "Fold results: [[12.690327644348145, 1.7223012447357178], [7.431137561798096, 1.3700714111328125], [7.226826190948486, 1.377320647239685], [7.522032737731934, 1.3776183128356934], [7.4249773025512695, 1.3683042526245117]]\n",
      "Average result: [8.45906029 1.44312317]\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list for storing results and a KFold object for 5-fold cross-validation\n",
    "results = []\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "# Cross-validation to evaluate model\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    reset_keras()\n",
    "    history = model.fit(X_train.reshape(-1, 9, 7, 1), y_train, epochs=50, batch_size=256, validation_data=(X_test.reshape(-1, 9, 7, 1), y_test), callbacks=[reduce_lr, early_stopping, checkpoint, tensorboard_callback])\n",
    "    reset_keras()\n",
    "    results.append(model.evaluate(X_test.reshape(-1, 9, 7, 1), y_test))\n",
    "\n",
    "# Output the results of cross-validation\n",
    "print(\"Fold results:\", results)\n",
    "print(\"Average result:\", numpy.mean(results, axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
