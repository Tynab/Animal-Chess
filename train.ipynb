{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy\n",
    "import os\n",
    "import pandas\n",
    "import tensorflow\n",
    "\n",
    "from datetime import *\n",
    "from sklearn.model_selection import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.regularizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Set NVIDIA GeForce RTX 3060 memory limit in MB\n",
    "GPU_LIM_MB = 1_024 * 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve a list of available GPUs\n",
    "gpus = tensorflow.config.list_physical_devices('GPU')\n",
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Set the memory limit for the first GPU\n",
    "if gpus:\n",
    "    try:\n",
    "        tensorflow.config.set_visible_devices(gpus[0], 'GPU')\n",
    "        tensorflow.config.experimental.set_virtual_device_configuration(gpus[0], [tensorflow.config.experimental.VirtualDeviceConfiguration(memory_limit=GPU_LIM_MB)])\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>board</th>\n",
       "      <th>side</th>\n",
       "      <th>piece</th>\n",
       "      <th>atk</th>\n",
       "      <th>move</th>\n",
       "      <th>river</th>\n",
       "      <th>trap</th>\n",
       "      <th>den</th>\n",
       "      <th>score</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3c303edc-80ac-422b-bf2c-8668724fdbf2</td>\n",
       "      <td>l-r---E-T-d-----C---p---W-------------w---P---...</td>\n",
       "      <td>-1</td>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>G7F7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3c303edc-80ac-422b-bf2c-8668724fdbf2</td>\n",
       "      <td>l--r--E-T-d-----C---p---W-------------w---P---...</td>\n",
       "      <td>1</td>\n",
       "      <td>r</td>\n",
       "      <td>1</td>\n",
       "      <td>A3A4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3c303edc-80ac-422b-bf2c-8668724fdbf2</td>\n",
       "      <td>l--r--E-T-d-----C---p---W-------------w---P---...</td>\n",
       "      <td>-1</td>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>F7G7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3c303edc-80ac-422b-bf2c-8668724fdbf2</td>\n",
       "      <td>l---r-E-T-d-----C---p---W-------------w---P---...</td>\n",
       "      <td>1</td>\n",
       "      <td>r</td>\n",
       "      <td>1</td>\n",
       "      <td>A4A5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3c303edc-80ac-422b-bf2c-8668724fdbf2</td>\n",
       "      <td>l---r--ET-d-----C---p---W-------------w---P---...</td>\n",
       "      <td>-1</td>\n",
       "      <td>E</td>\n",
       "      <td>8</td>\n",
       "      <td>A7A8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  3c303edc-80ac-422b-bf2c-8668724fdbf2   \n",
       "1  3c303edc-80ac-422b-bf2c-8668724fdbf2   \n",
       "2  3c303edc-80ac-422b-bf2c-8668724fdbf2   \n",
       "3  3c303edc-80ac-422b-bf2c-8668724fdbf2   \n",
       "4  3c303edc-80ac-422b-bf2c-8668724fdbf2   \n",
       "\n",
       "                                               board  side piece  atk  move  \\\n",
       "0  l-r---E-T-d-----C---p---W-------------w---P---...    -1     R    1  G7F7   \n",
       "1  l--r--E-T-d-----C---p---W-------------w---P---...     1     r    1  A3A4   \n",
       "2  l--r--E-T-d-----C---p---W-------------w---P---...    -1     R    1  F7G7   \n",
       "3  l---r-E-T-d-----C---p---W-------------w---P---...     1     r    1  A4A5   \n",
       "4  l---r--ET-d-----C---p---W-------------w---P---...    -1     E    8  A7A8   \n",
       "\n",
       "   river  trap  den  score  winner  \n",
       "0      0     0    0      0       0  \n",
       "1      0     0    0      0       0  \n",
       "2      0     0    0      0       0  \n",
       "3      0     0    0      0       0  \n",
       "4      0     0    0      0       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = pandas.read_csv('dark.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33093425"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the total number of rows\n",
    "count = len(df)\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     3c303edc-80ac-422b-bf2c-8668724fdbf2\n",
       "board     l----W--E-d---r-C---p-----T------P----w----tLc...\n",
       "side                                                     -1\n",
       "piece                                                     L\n",
       "atk                                                       7\n",
       "move                                                   F9E9\n",
       "river                                                     0\n",
       "trap                                                     -1\n",
       "den                                                       0\n",
       "score                                                    30\n",
       "winner                                                    0\n",
       "Name: 32, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the sample at index 32\n",
    "sample = df.iloc[32]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode chess pieces to integer\n",
    "def encode_piece(piece_char):\n",
    "    piece_mapping = {'-': 0, 'r': 1, 'c': 2, 'd': 3, 'w': 4, 'p': 5, 't': 6, 'l': 7, 'e': 8, 'R': -1, 'C': -2, 'D': -3, 'W': -4, 'P': -5, 'T': -6, 'L': -7, 'E': -8}\n",
    "    return piece_mapping.get(piece_char, 0)\n",
    "\n",
    "encode_piece(sample['piece'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.,  0.,  0.,  0.,  0.,  2.,  0.],\n",
       "       [ 0.,  3.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  5.,  0.,  4.,  8.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0., -1.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [-4.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., -5.,  0.,  0.,  0.],\n",
       "       [ 0., -2.,  0.,  0.,  6.,  0.,  0.],\n",
       "       [-8.,  0., -6.,  0., -7.,  0.,  0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode chess board to matrix\n",
    "def encode_board(board_str):\n",
    "    board_matrix = numpy.zeros((9, 7))\n",
    "    for i, piece in enumerate(board_str[::-1]):\n",
    "        row, col = divmod(i, 9)\n",
    "        board_matrix[col][row] = encode_piece(piece)\n",
    "    return numpy.flip(numpy.flip(board_matrix, 0), 1)\n",
    "\n",
    "encode_board(sample['board'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.,  0.,  0., ...,  0.,  0., -7.],\n",
       "       [ 7.,  0.,  0., ...,  0.,  0., -7.],\n",
       "       [ 7.,  0.,  0., ...,  0.,  0., -7.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode all chess boards\n",
    "df['board_encoded'] = df['board'].apply(encode_board)\n",
    "board_matrix_flattened = numpy.array(df['board_encoded'].tolist()).reshape(count, -1)\n",
    "board_matrix_flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((33093425, 63), (33093425,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare data for model training\n",
    "X = numpy.array(df['board_encoded'].tolist()).reshape(count, -1)\n",
    "y = df['score'].values\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Reset Keras session\n",
    "def reset_keras():\n",
    "    tensorflow.keras.backend.clear_session()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Build the model architecture\n",
    "def build_model(input_shape, activation='relu'):\n",
    "    # Create a sequential model\n",
    "    model = Sequential([\n",
    "        # Input layer specifies the shape of the input data\n",
    "        Input(shape=input_shape),\n",
    "        # First convolution layer with 128 filters\n",
    "        Conv2D(128, (3, 3), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Activation(activation),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        # Second convolution layer with 256 filters\n",
    "        Conv2D(256, (3, 3), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Activation(activation),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        # Flatten the output from 2D to 1D before passing to the dense layer\n",
    "        Flatten(),\n",
    "        Dense(2048, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dropout(0.5),\n",
    "        # Output layer with linear activation to predict a continuous value\n",
    "        Dense(1, activation='linear')\n",
    "    ])\n",
    "    # Compile the model with Adam optimizer and mean squared error loss\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='mean_squared_error', metrics=['mae'])\n",
    "    # Return the model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Create the neural network model with the specified input shape and activation function\n",
    "model = build_model((9, 7, 1), activation='leaky_relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Set up TensorBoard logging with a timestamped directory to monitor the training process\n",
    "log_dir = os.path.join(\"logs\", \"fit\", datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Initialize callbacks for adaptive learning rate, early stopping to prevent overfitting, and saving the best model\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint(\"best_model.h5\", monitor='val_loss', save_best_only=True, save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((33093425, 63), (33093425,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "103417/103417 [==============================] - 569s 5ms/step - loss: 222.3724 - mae: 7.1522 - val_loss: 83.6308 - val_mae: 3.9706 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "103417/103417 [==============================] - 532s 5ms/step - loss: 92.3235 - mae: 5.0864 - val_loss: 57.6835 - val_mae: 3.6376 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "103417/103417 [==============================] - 532s 5ms/step - loss: 72.5608 - mae: 4.5535 - val_loss: 64.3201 - val_mae: 4.7631 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "103417/103417 [==============================] - 515s 5ms/step - loss: 61.6155 - mae: 4.2123 - val_loss: 34.5451 - val_mae: 2.6118 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      "103417/103417 [==============================] - 510s 5ms/step - loss: 54.1167 - mae: 3.9386 - val_loss: 37.0597 - val_mae: 2.9990 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "103417/103417 [==============================] - 511s 5ms/step - loss: 48.5454 - mae: 3.7196 - val_loss: 30.1525 - val_mae: 2.4568 - lr: 1.0000e-04\n",
      "Epoch 7/50\n",
      "103417/103417 [==============================] - 510s 5ms/step - loss: 44.6435 - mae: 3.5794 - val_loss: 32.4483 - val_mae: 3.0330 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "103417/103417 [==============================] - 511s 5ms/step - loss: 42.1644 - mae: 3.4834 - val_loss: 25.7790 - val_mae: 2.1829 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "103417/103417 [==============================] - 510s 5ms/step - loss: 39.7526 - mae: 3.4048 - val_loss: 26.2255 - val_mae: 2.2637 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "103417/103417 [==============================] - 513s 5ms/step - loss: 37.7333 - mae: 3.3327 - val_loss: 27.1436 - val_mae: 2.6130 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "103417/103417 [==============================] - 499s 5ms/step - loss: 36.2876 - mae: 3.2830 - val_loss: 23.6535 - val_mae: 2.3487 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "103417/103417 [==============================] - 496s 5ms/step - loss: 35.0309 - mae: 3.2345 - val_loss: 21.3239 - val_mae: 2.0760 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "103417/103417 [==============================] - 497s 5ms/step - loss: 34.0642 - mae: 3.1944 - val_loss: 27.2681 - val_mae: 2.8888 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "103417/103417 [==============================] - 496s 5ms/step - loss: 33.1430 - mae: 3.1578 - val_loss: 34.3510 - val_mae: 4.0122 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "103417/103417 [==============================] - 497s 5ms/step - loss: 32.2465 - mae: 3.1239 - val_loss: 34.7755 - val_mae: 4.0929 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "103417/103417 [==============================] - 496s 5ms/step - loss: 31.5778 - mae: 3.0932 - val_loss: 29.6725 - val_mae: 3.0695 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "103417/103417 [==============================] - 496s 5ms/step - loss: 31.1508 - mae: 3.0694 - val_loss: 25.6089 - val_mae: 2.9558 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "103417/103417 [==============================] - 496s 5ms/step - loss: 24.1542 - mae: 2.6776 - val_loss: 13.0776 - val_mae: 1.5264 - lr: 2.0000e-05\n",
      "Epoch 19/50\n",
      "103417/103417 [==============================] - 497s 5ms/step - loss: 23.0674 - mae: 2.6432 - val_loss: 13.4578 - val_mae: 1.7153 - lr: 2.0000e-05\n",
      "Epoch 20/50\n",
      "103417/103417 [==============================] - 497s 5ms/step - loss: 22.5617 - mae: 2.6331 - val_loss: 12.9137 - val_mae: 1.6641 - lr: 2.0000e-05\n",
      "Epoch 21/50\n",
      "103417/103417 [==============================] - 497s 5ms/step - loss: 22.2791 - mae: 2.6278 - val_loss: 12.2820 - val_mae: 1.5518 - lr: 2.0000e-05\n",
      "Epoch 22/50\n",
      "103417/103417 [==============================] - 496s 5ms/step - loss: 21.9761 - mae: 2.6241 - val_loss: 12.6864 - val_mae: 1.7393 - lr: 2.0000e-05\n",
      "Epoch 23/50\n",
      "103417/103417 [==============================] - 497s 5ms/step - loss: 21.8689 - mae: 2.6242 - val_loss: 14.9376 - val_mae: 2.1772 - lr: 2.0000e-05\n",
      "Epoch 24/50\n",
      "103417/103417 [==============================] - 497s 5ms/step - loss: 21.5611 - mae: 2.6204 - val_loss: 12.1243 - val_mae: 1.4635 - lr: 2.0000e-05\n",
      "Epoch 25/50\n",
      "103417/103417 [==============================] - 1213s 12ms/step - loss: 21.3835 - mae: 2.6166 - val_loss: 12.8380 - val_mae: 1.7139 - lr: 2.0000e-05\n",
      "Epoch 26/50\n",
      "103417/103417 [==============================] - 1497s 14ms/step - loss: 21.2450 - mae: 2.6136 - val_loss: 11.7816 - val_mae: 1.5697 - lr: 2.0000e-05\n",
      "Epoch 27/50\n",
      "103417/103417 [==============================] - 1496s 14ms/step - loss: 21.0517 - mae: 2.6111 - val_loss: 11.8460 - val_mae: 1.4818 - lr: 2.0000e-05\n",
      "Epoch 28/50\n",
      "103417/103417 [==============================] - 1433s 14ms/step - loss: 20.9206 - mae: 2.6070 - val_loss: 11.9449 - val_mae: 1.6823 - lr: 2.0000e-05\n",
      "Epoch 29/50\n",
      "103417/103417 [==============================] - 1388s 13ms/step - loss: 20.7759 - mae: 2.6056 - val_loss: 11.0221 - val_mae: 1.4518 - lr: 2.0000e-05\n",
      "Epoch 30/50\n",
      "103417/103417 [==============================] - 1399s 14ms/step - loss: 20.7312 - mae: 2.6033 - val_loss: 10.9717 - val_mae: 1.4615 - lr: 2.0000e-05\n",
      "Epoch 31/50\n",
      "103417/103417 [==============================] - 1424s 14ms/step - loss: 20.5819 - mae: 2.6007 - val_loss: 11.3376 - val_mae: 1.6060 - lr: 2.0000e-05\n",
      "Epoch 32/50\n",
      "103417/103417 [==============================] - 1500s 15ms/step - loss: 20.4503 - mae: 2.5982 - val_loss: 11.1334 - val_mae: 1.4834 - lr: 2.0000e-05\n",
      "Epoch 33/50\n",
      "103417/103417 [==============================] - 1518s 15ms/step - loss: 20.3690 - mae: 2.5958 - val_loss: 14.7623 - val_mae: 2.3401 - lr: 2.0000e-05\n",
      "Epoch 34/50\n",
      "103417/103417 [==============================] - 1542s 15ms/step - loss: 20.2296 - mae: 2.5914 - val_loss: 11.6109 - val_mae: 1.4834 - lr: 2.0000e-05\n",
      "Epoch 35/50\n",
      "103417/103417 [==============================] - 1484s 14ms/step - loss: 20.1583 - mae: 2.5895 - val_loss: 11.2692 - val_mae: 1.5696 - lr: 2.0000e-05\n",
      "Epoch 36/50\n",
      "103417/103417 [==============================] - 1450s 14ms/step - loss: 19.2308 - mae: 2.5066 - val_loss: 10.4430 - val_mae: 1.4624 - lr: 1.0000e-05\n",
      "Epoch 37/50\n",
      "103417/103417 [==============================] - 1451s 14ms/step - loss: 19.0171 - mae: 2.4971 - val_loss: 10.1174 - val_mae: 1.3790 - lr: 1.0000e-05\n",
      "Epoch 38/50\n",
      "103417/103417 [==============================] - 1489s 14ms/step - loss: 19.0253 - mae: 2.4947 - val_loss: 10.3181 - val_mae: 1.4680 - lr: 1.0000e-05\n",
      "Epoch 39/50\n",
      "103417/103417 [==============================] - 1558s 15ms/step - loss: 18.9301 - mae: 2.4933 - val_loss: 9.7581 - val_mae: 1.3389 - lr: 1.0000e-05\n",
      "Epoch 40/50\n",
      "103417/103417 [==============================] - 1573s 15ms/step - loss: 18.8776 - mae: 2.4924 - val_loss: 10.4410 - val_mae: 1.5319 - lr: 1.0000e-05\n",
      "Epoch 41/50\n",
      "103417/103417 [==============================] - 1595s 15ms/step - loss: 18.8080 - mae: 2.4900 - val_loss: 10.4407 - val_mae: 1.4761 - lr: 1.0000e-05\n",
      "Epoch 42/50\n",
      "103417/103417 [==============================] - 1522s 15ms/step - loss: 18.7365 - mae: 2.4896 - val_loss: 9.7778 - val_mae: 1.3642 - lr: 1.0000e-05\n",
      "Epoch 43/50\n",
      "103417/103417 [==============================] - 1532s 15ms/step - loss: 18.6420 - mae: 2.4876 - val_loss: 9.8866 - val_mae: 1.4040 - lr: 1.0000e-05\n",
      "Epoch 44/50\n",
      "103417/103417 [==============================] - 1551s 15ms/step - loss: 18.6623 - mae: 2.4880 - val_loss: 9.6732 - val_mae: 1.3454 - lr: 1.0000e-05\n",
      "Epoch 45/50\n",
      "103417/103417 [==============================] - 1499s 14ms/step - loss: 18.5354 - mae: 2.4859 - val_loss: 10.0567 - val_mae: 1.4644 - lr: 1.0000e-05\n",
      "Epoch 46/50\n",
      "103417/103417 [==============================] - 1471s 14ms/step - loss: 18.5096 - mae: 2.4851 - val_loss: 10.1540 - val_mae: 1.4665 - lr: 1.0000e-05\n",
      "Epoch 47/50\n",
      "103417/103417 [==============================] - 1479s 14ms/step - loss: 18.4539 - mae: 2.4833 - val_loss: 9.7992 - val_mae: 1.3791 - lr: 1.0000e-05\n",
      "Epoch 48/50\n",
      "103417/103417 [==============================] - 1413s 14ms/step - loss: 18.3430 - mae: 2.4826 - val_loss: 9.6233 - val_mae: 1.3629 - lr: 1.0000e-05\n",
      "Epoch 49/50\n",
      "103417/103417 [==============================] - 1387s 13ms/step - loss: 18.3379 - mae: 2.4825 - val_loss: 9.4152 - val_mae: 1.3131 - lr: 1.0000e-05\n",
      "Epoch 50/50\n",
      "103417/103417 [==============================] - 1371s 13ms/step - loss: 18.3369 - mae: 2.4819 - val_loss: 9.6778 - val_mae: 1.3170 - lr: 1.0000e-05\n",
      "206834/206834 [==============================] - 717s 3ms/step - loss: 9.6778 - mae: 1.3170\n",
      "Epoch 1/50\n",
      "103417/103417 [==============================] - 1368s 13ms/step - loss: 19.1220 - mae: 2.4969 - val_loss: 6.4813 - val_mae: 1.3161 - lr: 1.0000e-05\n",
      "Epoch 2/50\n",
      "103417/103417 [==============================] - 1368s 13ms/step - loss: 19.0612 - mae: 2.4965 - val_loss: 8.1243 - val_mae: 1.7230 - lr: 1.0000e-05\n",
      "Epoch 3/50\n",
      "103417/103417 [==============================] - 1376s 13ms/step - loss: 18.9120 - mae: 2.4936 - val_loss: 6.8980 - val_mae: 1.4185 - lr: 1.0000e-05\n",
      "Epoch 4/50\n",
      "103417/103417 [==============================] - 1401s 14ms/step - loss: 18.9017 - mae: 2.4936 - val_loss: 7.3179 - val_mae: 1.4884 - lr: 1.0000e-05\n",
      "Epoch 5/50\n",
      "103417/103417 [==============================] - 1422s 14ms/step - loss: 18.7853 - mae: 2.4925 - val_loss: 7.4134 - val_mae: 1.5139 - lr: 1.0000e-05\n",
      "Epoch 6/50\n",
      "103417/103417 [==============================] - 1419s 14ms/step - loss: 18.7024 - mae: 2.4926 - val_loss: 7.3943 - val_mae: 1.5171 - lr: 1.0000e-05\n",
      "Epoch 7/50\n",
      "103417/103417 [==============================] - 1403s 14ms/step - loss: 18.6604 - mae: 2.4919 - val_loss: 7.4755 - val_mae: 1.5304 - lr: 1.0000e-05\n",
      "Epoch 8/50\n",
      "103417/103417 [==============================] - 1377s 13ms/step - loss: 18.5796 - mae: 2.4898 - val_loss: 6.7511 - val_mae: 1.3497 - lr: 1.0000e-05\n",
      "Epoch 9/50\n",
      "103417/103417 [==============================] - 1388s 13ms/step - loss: 18.6197 - mae: 2.4904 - val_loss: 6.8845 - val_mae: 1.3250 - lr: 1.0000e-05\n",
      "Epoch 10/50\n",
      "103417/103417 [==============================] - 1395s 13ms/step - loss: 18.5148 - mae: 2.4878 - val_loss: 7.2330 - val_mae: 1.4764 - lr: 1.0000e-05\n",
      "Epoch 11/50\n",
      "103417/103417 [==============================] - 1417s 14ms/step - loss: 18.4786 - mae: 2.4875 - val_loss: 7.0278 - val_mae: 1.3579 - lr: 1.0000e-05\n",
      "206834/206834 [==============================] - 646s 3ms/step - loss: 6.4810 - mae: 1.3161\n",
      "Epoch 1/50\n",
      "103417/103417 [==============================] - 1318s 13ms/step - loss: 18.8163 - mae: 2.4805 - val_loss: 6.9920 - val_mae: 1.4022 - lr: 1.0000e-05\n",
      "Epoch 2/50\n",
      "103417/103417 [==============================] - 1318s 13ms/step - loss: 18.6992 - mae: 2.4801 - val_loss: 6.8184 - val_mae: 1.3185 - lr: 1.0000e-05\n",
      "Epoch 3/50\n",
      "103417/103417 [==============================] - 1317s 13ms/step - loss: 18.6606 - mae: 2.4785 - val_loss: 7.9026 - val_mae: 1.6008 - lr: 1.0000e-05\n",
      "Epoch 4/50\n",
      "103417/103417 [==============================] - 1315s 13ms/step - loss: 18.5790 - mae: 2.4783 - val_loss: 6.8829 - val_mae: 1.3320 - lr: 1.0000e-05\n",
      "Epoch 5/50\n",
      "103417/103417 [==============================] - 1312s 13ms/step - loss: 18.5202 - mae: 2.4761 - val_loss: 8.2732 - val_mae: 1.6609 - lr: 1.0000e-05\n",
      "Epoch 6/50\n",
      "103417/103417 [==============================] - 1313s 13ms/step - loss: 18.4190 - mae: 2.4758 - val_loss: 7.1963 - val_mae: 1.4372 - lr: 1.0000e-05\n",
      "Epoch 7/50\n",
      "103417/103417 [==============================] - 1317s 13ms/step - loss: 18.3757 - mae: 2.4748 - val_loss: 6.8601 - val_mae: 1.2962 - lr: 1.0000e-05\n",
      "Epoch 8/50\n",
      "103417/103417 [==============================] - 1314s 13ms/step - loss: 18.3881 - mae: 2.4735 - val_loss: 7.1552 - val_mae: 1.3861 - lr: 1.0000e-05\n",
      "Epoch 9/50\n",
      "103417/103417 [==============================] - 1316s 13ms/step - loss: 18.2963 - mae: 2.4725 - val_loss: 7.0101 - val_mae: 1.3413 - lr: 1.0000e-05\n",
      "Epoch 10/50\n",
      "103417/103417 [==============================] - 1349s 13ms/step - loss: 18.3720 - mae: 2.4741 - val_loss: 7.1539 - val_mae: 1.3742 - lr: 1.0000e-05\n",
      "Epoch 11/50\n",
      "103417/103417 [==============================] - 1409s 14ms/step - loss: 18.2187 - mae: 2.4717 - val_loss: 7.0359 - val_mae: 1.3485 - lr: 1.0000e-05\n",
      "Epoch 12/50\n",
      "103417/103417 [==============================] - 1382s 13ms/step - loss: 18.1948 - mae: 2.4703 - val_loss: 7.3536 - val_mae: 1.4380 - lr: 1.0000e-05\n",
      "206834/206834 [==============================] - 730s 4ms/step - loss: 6.8185 - mae: 1.3185\n",
      "Epoch 1/50\n",
      "103417/103417 [==============================] - 1099s 11ms/step - loss: 18.9012 - mae: 2.5090 - val_loss: 6.7108 - val_mae: 1.2588 - lr: 1.0000e-05\n",
      "Epoch 2/50\n",
      "103417/103417 [==============================] - 851s 8ms/step - loss: 18.7469 - mae: 2.5069 - val_loss: 7.4072 - val_mae: 1.3859 - lr: 1.0000e-05\n",
      "Epoch 3/50\n",
      "103417/103417 [==============================] - 790s 8ms/step - loss: 18.7341 - mae: 2.5053 - val_loss: 7.5123 - val_mae: 1.4526 - lr: 1.0000e-05\n",
      "Epoch 4/50\n",
      "103417/103417 [==============================] - 749s 7ms/step - loss: 18.6503 - mae: 2.5050 - val_loss: 6.9632 - val_mae: 1.2742 - lr: 1.0000e-05\n",
      "Epoch 5/50\n",
      "103417/103417 [==============================] - 759s 7ms/step - loss: 18.5669 - mae: 2.5032 - val_loss: 6.8644 - val_mae: 1.2666 - lr: 1.0000e-05\n",
      "Epoch 6/50\n",
      "103417/103417 [==============================] - 756s 7ms/step - loss: 18.5049 - mae: 2.5019 - val_loss: 7.3805 - val_mae: 1.3339 - lr: 1.0000e-05\n",
      "Epoch 7/50\n",
      "103417/103417 [==============================] - 757s 7ms/step - loss: 18.4907 - mae: 2.5017 - val_loss: 7.0271 - val_mae: 1.2727 - lr: 1.0000e-05\n",
      "Epoch 8/50\n",
      "103417/103417 [==============================] - 773s 7ms/step - loss: 18.5073 - mae: 2.5008 - val_loss: 6.8806 - val_mae: 1.2832 - lr: 1.0000e-05\n",
      "Epoch 9/50\n",
      "103417/103417 [==============================] - 774s 7ms/step - loss: 18.3817 - mae: 2.4993 - val_loss: 6.8751 - val_mae: 1.3087 - lr: 1.0000e-05\n",
      "Epoch 10/50\n",
      "103417/103417 [==============================] - 712s 7ms/step - loss: 18.3919 - mae: 2.5001 - val_loss: 7.5184 - val_mae: 1.4103 - lr: 1.0000e-05\n",
      "Epoch 11/50\n",
      "103417/103417 [==============================] - 712s 7ms/step - loss: 18.3287 - mae: 2.4973 - val_loss: 7.2786 - val_mae: 1.3591 - lr: 1.0000e-05\n",
      "206834/206834 [==============================] - 510s 2ms/step - loss: 6.7112 - mae: 1.2588\n",
      "Epoch 1/50\n",
      "103417/103417 [==============================] - 1184s 11ms/step - loss: 18.7264 - mae: 2.4917 - val_loss: 6.7797 - val_mae: 1.3242 - lr: 1.0000e-05\n",
      "Epoch 2/50\n",
      "103417/103417 [==============================] - 1257s 12ms/step - loss: 18.6398 - mae: 2.4890 - val_loss: 6.8449 - val_mae: 1.2972 - lr: 1.0000e-05\n",
      "Epoch 3/50\n",
      "103417/103417 [==============================] - 1255s 12ms/step - loss: 18.5935 - mae: 2.4874 - val_loss: 6.5495 - val_mae: 1.2705 - lr: 1.0000e-05\n",
      "Epoch 4/50\n",
      "103417/103417 [==============================] - 1282s 12ms/step - loss: 18.5008 - mae: 2.4869 - val_loss: 7.2420 - val_mae: 1.3584 - lr: 1.0000e-05\n",
      "Epoch 5/50\n",
      "103417/103417 [==============================] - 1289s 12ms/step - loss: 18.4756 - mae: 2.4863 - val_loss: 8.0625 - val_mae: 1.5707 - lr: 1.0000e-05\n",
      "Epoch 6/50\n",
      "103417/103417 [==============================] - 1237s 12ms/step - loss: 18.4238 - mae: 2.4848 - val_loss: 6.6682 - val_mae: 1.2691 - lr: 1.0000e-05\n",
      "Epoch 7/50\n",
      "103417/103417 [==============================] - 1180s 11ms/step - loss: 18.4030 - mae: 2.4843 - val_loss: 6.9380 - val_mae: 1.3213 - lr: 1.0000e-05\n",
      "Epoch 8/50\n",
      "103417/103417 [==============================] - 1178s 11ms/step - loss: 18.3353 - mae: 2.4838 - val_loss: 6.9173 - val_mae: 1.2695 - lr: 1.0000e-05\n",
      "Epoch 9/50\n",
      "103417/103417 [==============================] - 1173s 11ms/step - loss: 18.2371 - mae: 2.4806 - val_loss: 7.5497 - val_mae: 1.4990 - lr: 1.0000e-05\n",
      "Epoch 10/50\n",
      "103417/103417 [==============================] - 1167s 11ms/step - loss: 18.2048 - mae: 2.4808 - val_loss: 6.9749 - val_mae: 1.2882 - lr: 1.0000e-05\n",
      "Epoch 11/50\n",
      "103417/103417 [==============================] - 1157s 11ms/step - loss: 18.1946 - mae: 2.4805 - val_loss: 7.2067 - val_mae: 1.3182 - lr: 1.0000e-05\n",
      "Epoch 12/50\n",
      "103417/103417 [==============================] - 1163s 11ms/step - loss: 18.2495 - mae: 2.4804 - val_loss: 7.0612 - val_mae: 1.3667 - lr: 1.0000e-05\n",
      "Epoch 13/50\n",
      "103417/103417 [==============================] - 1197s 12ms/step - loss: 18.0946 - mae: 2.4776 - val_loss: 6.8222 - val_mae: 1.3138 - lr: 1.0000e-05\n",
      "206834/206834 [==============================] - 528s 3ms/step - loss: 6.5497 - mae: 1.2706\n",
      "Fold results: [[9.677840232849121, 1.317033052444458], [6.48101806640625, 1.3160851001739502], [6.818532466888428, 1.318500280380249], [6.711207866668701, 1.2588261365890503], [6.5497307777404785, 1.2705509662628174]]\n",
      "Average result: [7.24766588 1.29619911]\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list for storing results and a KFold object for 5-fold cross-validation\n",
    "results = []\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "# Cross-validation to evaluate model\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    reset_keras()\n",
    "    history = model.fit(X_train.reshape(-1, 9, 7, 1), y_train, epochs=50, batch_size=256, validation_data=(X_test.reshape(-1, 9, 7, 1), y_test), callbacks=[reduce_lr, early_stopping, checkpoint, tensorboard_callback])\n",
    "    reset_keras()\n",
    "    results.append(model.evaluate(X_test.reshape(-1, 9, 7, 1), y_test))\n",
    "\n",
    "# Output the results of cross-validation\n",
    "print(\"Fold results:\", results)\n",
    "print(\"Average result:\", numpy.mean(results, axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
